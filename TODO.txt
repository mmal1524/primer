# Priorities

## Useful books (?)

https://openintro-ims.netlify.app/
https://statswithr.github.io/book/ ()
https://www.bayesrulesbook.com/

https://statswithr.github.io/book/bayesian-inference.html#continuous-variables-and-eliciting-probability-distributions

https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view

https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/binomial-random-variables/v/binomial-distribution

## Mahima

## Arghayan

# Topics

* Output created: docs/index.html
Warning message:
In readLines(file) :
  incomplete final line found on '/var/folders/mk/lh99bg295msg8myvcf5yczkc0000gn/T//RtmpgXdsMq/file171757d88bd09'

* Get rid of map() and list-columns in Chapter 6, given that we cut out the explanation of them in Chapter 3. Or maybe we could add them back in to chapter 3 or somewhere . . .? That is,

* Work on Chapter 11. Revisit Cardinal Virtue discussion in chapter 5. Does it belong there? Or in Chapter 6? Or nowhere?

* Get rid of 90% of the parameter interpretations discussions. Parameters, much less the posterior distributions of parameters, are not that interesting. We don't care with complex models, so we should not care (much) with simple models. Got a substantive question? Ask it directly as a newobs.
* Use the new tigris::shift_geometry() in map chapter to make Alaska, Hawaii easier to include in US maps. Example: https://gist.github.com/walkerke/6025153da606ee8711a77f689196299e.

* Need to add discussion, or at least links, which explain R Markdown and R Projects.

* Use chrome_print() to make PDF files instead of having to worry about tinytex and other arcana: https://rdrr.io/cran/pagedown/man/chrome_print.html


* When do we start using the new pipe? Whenever that is, we will want to update Getting Started to make the new pipe the default for CMD-shift-M. Presumably, there is a command for doing so. Discussion: https://blog.rstudio.com/2021/06/09/rstudio-v1-4-update-whats-new/

* Add one or two other types of models. Maybe stan_gamm4(), for generalized additive models, or stan_polr(), for ordinal models. Or both? Idea is that the basic purpose of Justice is to choose a functional form. Given that, we ought to have a bunch of functional forms which we try. Sure wish that there were a stan_multilogit(), which would be an easy extention from logistic. (Maybe there is? I need to explore the different family arguments in stan_glm().) Something for time series might also be useful, given how common time series are in reality. Or maybe we can stick with stan_glm() and just use one of the other 6 or 7 family options. Maybe Gamma, which ensures that the outcome is positive. (Example: https://mc-stan.org/rstanarm/articles/continuous.html). Or poissson? Some of this might work well in chapter 8, since some of the left-hand side variables have few possible value and/or are always positive. multinomial/categorical regressions are available in the brms package. One way to still use rstanarm for this is discussed here: https://github.com/stan-dev/rstanarm/issues/20, trick is using Poisson count models.


Wisdom: Begin with the ideal Preceptor Table. Depends on the question. Might be all voters in Massachusetts. Might be just the Republican voters. This determines if we are causal or predictive.  Key is that sometimes you want to know multiple potential outcomes for person X. If so, you are doing a causal model. If, however, you only need to know one outcome --- often because just one outcome is conceivable --- then it is predictive. The ideal Preceptor table will generally not have any rows for data we actually have. We never really care about the causal effect in election X specifically. We want to make claims about elections in general.

Then look for data and explore that data. What must I assume about the population, to allow me to go forward? If the data is not "close enough" to my ideal Preceptor Table, I give up. Wisdom is about knowing when to quit. Going forward means assuming that the actual data and the data from the ideal Preceptor Table come from the same population.


With population, we make a distinction between Wisdom --- Are the rows from the same population? --- and Justice --- Are the rows we have data for *representative* of thar population? That works nicely! Can we do the same thing wit columns? In our ideal Preceptor Table, we have a column called "treatment" which specifies the postcards we might send. With Wisdom, we need to decide if that treatment is drawn from the same population (?) of conceivable treatments as the "treatment" which was used in our data. Are the different things labelled "treatment" close enough that we can stack them in the same tibble? If no, then we give up. We can't go further.



Justice: Actual Preceptor Table, which is different from the ideal Preceptor Table in two ways. First, it includes the data we have. That is, it has more rows. Second, it has a bunch of missing values. (We could make an artificial distinction and say that the ideal Preceptor table never includes rows for data we have, but that is probably a bidge too far. Then again, with a time column, it is almost always true.) Then, representativeness (rows), validity (columns). In the ideal case, the data we have is perfectly representative of the population we want to estimate. That is, it is a random sample. In the ideal case, the columns mean the same thing in all rows. They are perfectly valid, but that is often not true.

If we lack perfect representativeness and/or perfect validity, then we can try to fix our mathematical structure. Or, we can just keep those failures in the back of our mind and then approach the posteriors we create

Assignment mechanism? Sampling mechanism?

Problem sets which use fake data which has been manipulated to violate the assumptions which students are making. Show them Preceptor's Posterior and compare it to their own.


Only the main functional form, with no variable names. Discussion of the error term.

Courage: For each model, write down the math, estimate the model, say something sensible about the regression table. Testing is stupid.

Temperance. Answer the question. Create a newobs, plug it into the model, calculate the outcome. Don't forget to add the error term of you are predicting. Then plot it. Be aware of the limits to the accuracy of your answer. Preceptor's Posterior.  All the cool themes. Bring it all together. Make the students say "Ahhh!" -->



* Preceptor's Posterior is a posterior for which all the assumptions are true. Just because the biog Data Science Marchine has spat out a posterior does not mean that you should believe it blindly.

* Replace geom_histogram with ggdist throughout, although leave the first example and show how ggdist just makes everything easier.

* Look to this for motivation: https://mc-stan.org/rstanarm/articles/continuous.html

* Need to add fig.cap to any R code chunk for a figure which we want to reference. "If we assign a figure caption to a code chunk via the chunk option fig.cap, R plots will be put into figure environments, which will be automatically labeled and numbered, and can also be cross-referenced."

* Fix these messages:

Output created: docs/index.html
Warning messages:
1: `group_by_()` was deprecated in dplyr 0.7.0.
Please use `group_by()` instead.
See vignette('programming') for more help
This warning is displayed once every 8 hours.
Call `lifecycle::last_warnings()` to see where this warning was generated.
2: In readLines(file) :
  incomplete final line found on '/var/folders/mk/lh99bg295msg8myvcf5yczkc0000gn/T//RtmpEkLaaY/file15f594e4d12d7'



* Use ragg? ragg can be used when knitting Rmarkdown files by setting dev="ragg_png" in the code chunk options

https://www.tidyverse.org/blog/2021/02/modern-text-features/

* Add the notion of Preceptor's Posterior earlier.


* Prevent the rayshader images from popping up when Chapter 5 is knitted.

* Add something about searching Github to help.

* Stop spending time interpreting coefficients. Make fun of the practice. Instead, just ask a question and then answer it.

* $ git reset --soft HEAD~1

* fmt_markdown() would allow us to have vertical elipses in the Preceptor Tables.

* Discuss ps_2 to PS_2 problem on Github.

* Discuss relative paths and home directories more in Tools.

* Discuss col_types in read_cvs().

* Add grouping for line plots.

* Explaing age*gender versus age:gender distinction?

* Get rid of joins except left joins, and mention the others.

* Think about the difference between the *posterior distribution* of average height and the *posterior probability distribution*. Right now, we only use the latter. But the draws which are produced from epred() and predict() are really more examples of the former. Aren't they? That is, 4,000 height values is a *distribution*, as are all vectors, and it is *posterior* since we created it with a function that starts with "posterior". But nor is it a probability distribution since we have not normalized it yet. Shouldn't we weave this connection throughout the book.

* Should I use MAD_SD, MAD, mad or what? Should be consistent.

* Standardize use of "tidyverse". Only two choices: Either Tidyverse, when referring to the concept and/or to the collection of packages, or **tidyverse**, when referring to the package itself. Never use "tidyverse."

* Add ModernDive common problems isssues: https://moderndive.com/C-appendixC.html#data-wrangling

* https://leanpub.com/markua/

* https://education.rstudio.com/blog/2021/02/cbds/

* Start using "When comparing" everywhere.

* Fix tools to include discussion of Git for Windows and setting up the Terminal correctly: https://happygitwithr.com/shell.html#windows-shell-hell.

* Split maps into census and maps. Combine with ipums. Add code for making ipums graphics.

* Every model should feature a plot of predicted values and true outcomes. The decomposition is fine as far as it goes, but it is not the key image.

* Think harder about p() and Prob(). Which goes where?

* Use fitted() or predict() or both?

* Need testing in each chapter.

* Find/remove all usage of "controlling for x, we see". Use "adjust" instead.

* What do we think about the width of the code in the book? Sure seems like the comment lines go on for too long. Maybe? I don't like the way they care cut off in my Ipad, but . . . do many students read on Ipads?

* https://xkcd.com/2048/

* Show the secret weapon of doing the same regression many times and then gathering the results. nest_by(), perhaps.

* Better automated grading? https://ubc-dsci.github.io/rudaux

* The elipses should be vertical, not horizontal in all Preceptor Tables.

* Discuss the meaning of sigma more often. Really only need one sentence, but should give that sentence almost every time.

* Include links to disputes about governors work:

https://erikgahner.dk/2020/a-response-to-andrew-gelman/
https://statmodeling.stat.columbia.edu/2020/07/02/no-i-dont-believe-that-claim-based-on-regression-discontinuity-analysis-that/
https://github.com/jonspring/discontinuity/blob/master/fileb23c55435f90.gif


* Make rayshader movies for all the 3D plots in Chapter 5. Guidance:
https://joeystanley.com/blog/3d-vowel-plots-with-rayshader

* Expand the Shiny appendix to highlight those aspects of Shiny that are most used by students for their final projects. Start with panel tabs. And math. And regression tables. Maybe switch the entire focus to the Mastering Shiny book? Are there cool things in Shiny 1.6 to discuss?

* Greek letters are for parameters which we can never observe. Latin letters are for observables.

* Explain transformations and centering, and maybe normalization as well. Sometimes we want to measure height in centimenters, sometimes in feet. Sometimes using z-scores is best. Sometimes percentiles. Discuss continuous versus categorial variables. Is there room to do this in chapter 7, or at least to introduce it. Or doe this wait till chapter 9?

* Chapter 7 should introduce, gently, the concept of in-sample and out-of-sample. As well as predictive accuracy as being a good way to judge how good your model is. What are some useful measures of predictive accuracy? Discuss our objective functions; minimize what? when would median be better than mean? Find a skewed data set and show how guessing the median works better than guessing the mean, if you care about absolute difference. (Can we estimate the median with stan_glm()?) Bias/Variance == Underfitting/Overfitting

* First, we can just print it. Chapter 7 walks the reader through all the parts of a stan_glm() model in detail. Later chapters will also show the printed model, but can move more quickly. Second, we create a summary table of the model using **gtsummary**. Note that this is just a different view of the same model. We don't show some things --- like sigma --- that we did show when just printing. We do show other things, like the 95% confidence interval which we did not show before. Neither is better! We use the one which is most helpful to our audience. Third, we use **tidybayes** to show histograms of the posterior distributions. The posterior is the underlying reality, the closest to the "truth" which we are going to get. The printed and table outputs are just summaries of the posterior. We might not show all three things every time, but we certainly always show the posterior. Graphics are pretty!

* After noting this formula, each example should create a plot with three histograms in a row --- left-to-right, the outcome (i.e., a histogram or density of Y), the fitted values (which is sometimes a spike, sometimes two spikes and so on) and, finally, the residuals. This highlights how we have *decomposed* the outcome into two parts: the model and the unmodeled variation. This belongs in the Courage chapter because it is a way of understanding the model we have made.

* We need a "machine" which generates these predictions, which is the same thing as a machine which fills in all the question marks in the Actual Preceptor Table, which is the same thing as a machine which produces "fake data" which looks a lot like our actual data.


* This also leads directly to the concept of *posterior predictive checks*, which is just fancy terminology for helping to see if your model makes sense. If your model is reasonable, then you would expect to see Z (a feature of the real data) in either new data or in fake data generated by your model. If you see Z, then you should have more faith in your model. If you don't, then something is wrong.

## To Discuss Later

* Fix this for next fall: https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/

* Discuss: Should "posterior probability distribution" become "ppd" or "PPD" everywhere?


* Track down these warnings from the end of book-building. Not sure where they come from.

Output created: docs/index.html
Warning messages:
1: Removed 19 rows containing missing values (geom_point).
2: The label(s) fig:histogram not found

DK: I think this is chapter 1 and the use of xlim!


* Lots of interesting items: . I like the hack of making your Rmd an index.Rmd and then the html will appear as a Github pages for free.


* Should use summary(fit_1) and discuss at some point. But when? Maybe Chapter 10?

* Do we need a cool graphics appendix, with  brief descriptions, pretty pictures from cool packages like: ggrepel, gghighlights, plotly. Others?

* posterior package useful?

* More discussion of what it means to "control for" something in a regression. Right now, we don't mention this until chapter 11. Needs to be covered earlier, especially in chapter 9. That sets the stage for later.

* Use tidybayes? Or just ggdist?


* Standardize notation. What are predicted/fitted values? Use y_i everywhere, instead of using problem specific terms? That seems a bad (good?!) idea.

* Generate some error messages and then show that they can teach you something. Object does not exist. filter only have one equal sign, and so on. Do this all the time. Normalize the generation and processing of error messages.

* Discuss base R versus tidyverse so that students are not confused when they see base R. Maybe this is week 3 in functions? And have a tutorial for this.

* Teach more file management, organization, use of R scripts. (Should have done that in some of the problem sets. Maybe a milestone could require that the graphic is created with a .R script with an image saved and then placed in the app directory.) Maybe add to tools? Create a tutorial for week 4?


*  Better workflow, automatic (with click confirmation) replacement of docs/ after successful check. Two parts: First, change the check so that it builds the book nicely. (Maybe not necessary. Maybe building the book in junk/ is OK?) Second, move the newly created book --- once it is accepted --- to docs/ on the master branch. Should we be taking multiple branches more seriously. Probably.
  + Things to discuss:
    - This change will prevent authors from easily knitting individual chapters. I will explore alternatives.
    - Two ways of handing auto-building and auot-updating:
      - 1) Create a new development branch. Students will submit PR to that branch. When you are ready, you can send a PR to merge to the master
           branch. The changes will only be live when you merge the development branch to the master branch.
      - 2) Keep things as they are. Once a student submits a PR, the build will directly go into docs/ and if successful, you can accept the PR
           and the new changes to the book will immediately be live. If the build check fails, do not accept the PR or else the deployment might
           break.



## Older Material

Everything below needs to be reviewed and organized.

Interesting resources:



Discuss how to set a stable version of primer.data which we do not touch all semester, and then have a devel branch in which we are fixing all the mistakes.


Clean up bok repo to test this:

rm -rf .git
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/PPBDS/primer.data.git
git push -u --force origin master

Add necessary references to the references.bib and ensure that they are called correctly.

## Social Media Plan

1) Students look at three main things when deciding to take a course (sent from one of our new followers on Instagram!):
  - Q Guide scores and reviews
  - The professor (or preceptor!)
  - Anecdotal stoties from friends

2) We need more from you! Pictures and vertical videos for Instagram about your everyday life. Students value the human connection even more in remote learning.

3) We also need more from Gov 50 alumn! I have an interactive story that will go up once we hit 250 followers that alumn will share. We can also create sponsored posts/stories if students are interested. I have already approved my personal account and will post a sponsored post soon.

4) Advertising logistics:
  - We can target 18-22 year-old users associated with Harvard College and living in the US.
  - $25 total, $5/day campaign will have an estimated reach of 2,500-6,600 accounts.
  - Depending on your budget, I suggest we run 2-4 of these campaigns in August.
  - Each campaign will promote one of our best performing posts: I have some appropriate memes scheduled to post soon and Q Guide Score Quotes.

## Book Building

* [*Bookdown*](https://bookdown.org/yihui/bookdown/) is the key reference. Build the book by following the instructions in _bookdown.yml. Those instructions end with a deployment to Github Pages via the doc/ directory.


## Things That Annoy Us

These are open projects with annoying details that we will revisit.

* ms-errors and simpsons-paradox. What do we do?

## Open Questions

* Need to start using tidybayes and ggdist. https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-rstanarm.html


* Is there a way to print out messages during the book building process so that you know where the process is? Maybe just a cat message at the end of Summary? Recall that we can't (?) use R code chunk names because duplicate code chunk names cause (still?) the process to blow up.


* Can you rebuild just a single chapter and then commit/push it? Right now, I have to rebuild the whole thing each time I want to make a single change. Takes too long.



## Other Items


* Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY




Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

https://committedtotape.shinyapps.io/freeR/


Replace all photos of activities with photos from Harvard, using Tsai.


# Appendices

Appendices have information that either a) a prof might reasonably decide not to assign or b) often contain material that students already know.

* Why Bayes?

* Messed up research articles. We need to prepare case studies of messed up articles. Start with those that Gelman cites. The tricky part is trying to figure out how to include these in class. And during which week do we use them.


* All the math you don't need to know. Bayes Theorem. Formulas. Normal distribution. Central limit theorem

* Advanced graphics, especially a tour of cool packages, including ggplotly and leaflet. gghighlight. ggstream.

* List of cool packages, googlesheet4 examples. : https://datavizm20.classes.andrewheiss.com/example/10-example/

* How to make an Rpubs and gists and saveWidgets:
https://datavizm20.classes.andrewheiss.com/example/10-example/

* Tufte and other graphics luminaries

* Leamer and other famous articles

* rtweet

* Making memes. Someone should figure out which meme maker is best for R. Or maybe we make our own. And then we make lots of memes for the book!

* Map appendix should include some Matt Blackwell examples.




# From the Bookdown book

preview_chapter() and serve_book() as an aid to chapter writers.

webshot() tool for including images taken from webpages. Everytime we mention how cool source X is, we should provide a webshot of it. (And we should test that it exists.) Make the productivity chapter include way less of our prose.


p. 64 notes that adding the suffix 2 to various output formats gives you all the cool stuff, like figure captioning and numbering.

p. 74 has a useful discussion of configuration options for the _bookdown.yml file.

* rmd_subdir are subdirectories to search for source Rmd files. That seems critical for my submodule structure.

* output_dir is the output directory of the process (_book by default).

* clean is vector of files and directories to be cleaned by the clean_book() function.

pp. 5-6 discuss rmd_files as the way to define your own ordering for output files. This also goes in the _bookdown.yml file.








## Next Summer


* Consider this for entire document:
html_document:
    code_folding: "hide"

* Other links of interest:

https://r-charts.com/ (use these tutorials)
https://www.youtube.com/watch?v=CQS4xxz-2s4 (marginal and conditional distributions; quite hard; maybe optional?)


* To Blog:

Entry about best class.
Why Bayesian

* Books

https://rstudio4edu.github.io/rstudio4edu-book/
https://ubc-dsci.github.io/introduction-to-datascience/
https://monika76five.github.io/ProbBayes/
https://bookdown.org/roback/bookdown-BeyondMLR/
https://dtkaplan.github.io/DataComputingEbook/

* Courses

https://ubc-dsci.github.io/dsci-100/
https://dataviz-2021.netlify.app/
https://jmbuhr.de/dataIntro20/
https://athanasiamo.github.io/tidyquintro/

* Other

https://evamaerey.github.io/flipbooks/about (use flipbooks for classroom exercises?)
https://nickch-k.github.io/EconometricsSlides/
https://holtzy.github.io/Pimp-my-rmd/

 https://fromthebottomoftheheap.net/2020/04/30/rendering-your-readme-with-github-actions/
 https://github.com/itsyaoyu/github_actions/blob/master/.github/workflows/main.yml
 https://www.willandskill.se/en/deleting-your-git-commit-history-without-removing-repo-on-github-bitbucket/

https://mdbeckman.github.io/JSM2020-Virtual/

* More cartoons like [xkcd](https://cran.r-project.org/package=RXKCD)

styler package

https://storywrangling.org/

https://desiree.rbind.io/post/2019/making-tip-boxes-with-bookdown-and-rmarkdown/ for making pretty boxes in the book

https://github.com/wikimedia/waxer for Wikipedia data

http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/

https://github.com/agmath/AppliedStatsInteractive

https://github.com/moodymudskipper/flow

https://github.com/ucbds-infra/ottr-sample

https://github.com/allisonhorst/stats-illustrations

https://bookdown.org/yihui/rmarkdown-cookbook/equatiomatic.html

Consider Netifly: https://cerebralmastication.com/2019/05/11/publishing-bookdown-to-netlify-automagically/

https://kieranhealy.org/categories/visualization/

https://openintro-ims.netlify.app/

https://education.rstudio.com/blog/2020/07/gtsummary/
https://moderndive.github.io/moderndive_labs/index.html
https://education.rstudio.com/blog/2020/07/learning-learnr/
https://rmarkdown.rstudio.com/authoring_shiny_prerendered.HTML

https://rstudio-education.github.io/tidyverse-cookbook/. I love this image: https://twitter.com/icymi_r/status/1407199200627113989/photo/1



## Miscelaneous

* New graphics? https://www.openscapes.org/blog/2020/10/12/tidy-data/

* Use tidybayes package for better graphics throughout? 

* Look at the **flair** package to format the code. Or does that require us to have two copies of code: working copy and colored copy? https://education.rstudio.com/blog/2020/05/flair/

* Does using **flipbookr** make sense in the middle of a chapter?

* https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.


Take a look at drat.


## Students

Heather and Kevin -- chapter 1
Ajay -- chapter 2
Anmay -- chapter 3
Sophia and Arghayan -- chapter 4
Yuhan -- chapter 5
Ryan -- chapter 6
George -- chapter 7
Mahima -- chapter 8
Mak -- Chapter 10


Nuo Wen -- technical issues
Ahmet -- Python
Shreeram -- hurricane








