<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 One Parameter | Preceptor’s Primer for Bayesian Data Science</title>
<meta name="author" content="David Kane">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.8/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script><script src="libs/plotly-binding-4.9.3/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet">
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script><script src="libs/rglWebGL-binding-0.106.8/rglWebGL.js"></script><link href="libs/rglwidgetClass-0.106.8/rgl.css" rel="stylesheet">
<script src="libs/rglwidgetClass-0.106.8/rglClass.min.js"></script><script src="libs/CanvasMatrix4-0.106.8/CanvasMatrix.min.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Preceptor’s Primer for Bayesian Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preamble.html">Preamble</a></li>
<li><a class="" href="getting-started.html">Getting Started</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">1</span> Visualization</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">2</span> Wrangling</a></li>
<li><a class="" href="data.html"><span class="header-section-number">3</span> Data</a></li>
<li><a class="" href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></li>
<li><a class="" href="probability.html"><span class="header-section-number">5</span> Probability</a></li>
<li><a class="active" href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></li>
<li><a class="" href="two-parameters.html"><span class="header-section-number">7</span> Two Parameters</a></li>
<li><a class="" href="three-parameters.html"><span class="header-section-number">8</span> Three Parameters</a></li>
<li><a class="" href="four-parameters.html"><span class="header-section-number">9</span> Four Parameters</a></li>
<li><a class="" href="five-parameters.html"><span class="header-section-number">10</span> Five Parameters</a></li>
<li><a class="" href="n-parameters.html"><span class="header-section-number">11</span> N Parameters</a></li>
<li><a class="" href="tools.html">Tools</a></li>
<li><a class="" href="functions.html">Functions</a></li>
<li><a class="" href="maps.html">Maps</a></li>
<li><a class="" href="ipums.html">IPUMS</a></li>
<li><a class="" href="animation.html">Animation</a></li>
<li><a class="" href="set-up-for-working-on-the-primer.html">Set Up for Working on The Primer</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PPBDS/primer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="one-parameter" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> One Parameter<a class="anchor" aria-label="anchor" href="#one-parameter"><i class="fas fa-link"></i></a>
</h1>
<!-- Chat with Yuhan. Map functions and list-columns are taught in chapter 5, both the Primer and the tutorial. Take look. Ensure that Chapter 5 covers clearly anything you use. -->
<!-- Read Chapter 7 again. We do not want to be so detailed in Chapter 6! In particular, I don't feel the need to understand fit_1. Nor do I care about parameters. Just using this as a black box, which allows me to answer questions. Which doesn't mean that we don't want several paragraphs about the box. Examples of stuff like: How do we calculate the probability that the true value of p is below 0.3? You can't give too many examples of area under the curve. -->
<!-- Fix answering the question section. Key is explaining what objects like ppd_for_p are. How to plot them. How to use them to answer questions. -->
<!-- Make the Overview tutorial match the chapter. -->
<!-- Delete any images we no longer need. -->
<!-- Why doesn't the percentage red match between the physical urn and the virtual urn? -->
<!-- Older comments: -->
<!-- 6.3 Sample size (What happens when we change sample size?) -->
<!-- Questions: I feel like we need more explanation about confidence intervals. Also do we want to differentiate between calculating an unknown population proportion and an unknown mu? Nonetheless I feel like understanding that if we take a simple random sample, how to construct a 95% confidence interval using $\bar{x}$ +/- 2(SD), because I feel like it is not emphasized how cool it is how our samples will be normally distributed no matter if if our population is normally distributed, but this could be too much statistics. Also do we introduce N(mu, SE) for a sample? If we went this route we would have to explain the normal distribution and the properties of the normal distribution in more detail, but I think in the long term it would help students to understand studies that include terminology like margin of error, confidence intervals, & p + a values. I feel like like the additional explanations and math would be worth it because you see that terminology come up ALOT. Don't even explain the math, just give good logical explanations with lots of graphics and explain which functions to use.  -->
<!-- 1. Comparing sampling distributions:  -->
<!--  - a. What is a sampling distribution? Introduce some vocab, but cut out unessential stuff (vocab is boring). Emphasize that this is a model, and we will never have the sampling distribution in real life. Also create vocab distinctions. Although the actual sampling distribution consists of many more trials, 1,000 is large enough for our purposes, and as such we will refer to distributions with many trials as sampling distributions.  -->
<!--  - b. Re-factoring our code: Start with a question: How do the sampling distributions of shovel sizes 25, 50, and 100 compare. Then make 3 separate variables. Yuck! Re-factor our code to make one tibble, using both mapping and expand_grid().  -->
<!--  - c. Variance: Make 3 graphs to explain variance.  -->
<!--  - End section with finding standard deviation of each sampling distribution. Foreshadow that this is related to the Standard Error.   -->
<!--  - In this section readers will make the facet wrapped graph, the colored graph of 1,000 p values for each shovel size, and the line graph that plots standard deviation against shovel size.  -->
<!-- 2. Standard deviation and standard error:  -->
<!--  - a. Standard Deviation: We just took the standard deviation of sampling distributions for different shovel sizes. What are the implications? Use graphs of the 3 different sampling distributions but add sd and mean lines. Explain that the mean is the same as the population proportion. When we have a larger sample size, our samples are more likely to be close to the real population proportion.  -->
<!--  - b. Standard Error: Standard deviation of a point statistic. Before we were looking at our entire population. Now we look at a single sample, and ask ourselves how close/how far is this from the real population parameter. This is standard error, and it is related to standard deviation: When the standard deviation of our sampling distribution is low, each sample more likely to be closer to the real pop parameter, and as such each individual sample is more likely to have a smaller standard error.  -->
<!-- 3. SE and SD equations:  -->
<!--   - a. Vocab: Reuse stuff from current section, maybe cut back a little.  -->
<!--   - b. Standard deviation for a population proportion: Show the equation (sqrt(p(1-p)/n)) for calculating standard deviation. Overlay sd equation on the graph of 100 sample sizes as well as the facet wrapped graph to show that they produce the same result.  Make sure to use mean of sampling distribution for our estimate of p.-->
<!--   - c. Standard error for a population proportion: Replace p with p hat. We are now working with one sample.  -->
<!--   - d. difference between mean and p using vocab.  -->
<!--   - e. Equations for sd and se for a population mean. Include an image or two for understanding, but do not go into too much depth (that is for the next section) -->
<!-- 4. SE in practice: -->
<!--   - Start with a question: Ex. If we sample 17 out of 50 beads red, what proportion of beads in the whole urn are red?  -->
<!--   - a. Explaining the theoretical sampling distribution as a whole vs. taking one sample from the distribution. Differentiate standard deviation from standard error. -->
<!--   - b. Do some vocab stuff. We need to assume our sample is random. Repeat essential terms like "sampling distribution", "phat", and "p" to really reinforce them and show their applications in a specific problem. Explain how our one random sample exists somewhere in the sampling distribution, we just need to figure out how close it is to the actual population proportion.  -->
<!--   - c. End with a confidence interval. Include graph of confidence interval of each sample, and how the actual population proportion will fall within 95% of confidence intervals. Maybe make crosstalk plot.  -->
<!-- 6.4 Putting everything together -->
<!-- -Goals: Apply everything from the previous sections to answer 2 questions:  -->
<!-- - 6.4.1: The Questions: In a well mixed urn with an unknown number of red and white beads, we get 17 red beads in a random sample of size 50. (Should we use data on more than 1 sample? Also should the questions be hunger games themed?) -->
<!-- 1. What proportion of beads in the urn are red?  -->
<!-- 2. What is the probability that we will draw more than 8 red beads if we use a shovel of size 20?  -->
<!-- Questions: Should we go into more detail about how our one sample of 17 forms a confidence interval which we can use to estimate the population proportion? As of now we kind of just accept that our one sample of 17 is good enough instead of evaluating if it is a good representation of our population, and quantifying how certain we are that our sample represents our population. This would be a good way to further use Standard Error, because I feel as if we introduce it just to never use it again. Also, is it acceptable to use rbinom() to represent our population instead of sampling directly from the population? I did a test and using rbinom() produced an answer that was 1% different than sampling from the population, but obviously both answers involve alot of chance and a slight difference makes sense. Furthermore, I am also slighly concerned that using rbinom() a second time for the second question may be incorrect, so it may be more worthwhile to keep the shovel size constant and use the same data that we used for the first question.  -->
<!-- - 6.4.2: Wisdom: -->
<!-- -- 6.4.2.1: One parameter: Explain that, like the section alludes to, we are finding one parameter for the population. Walk through the thought process on how we need to find the one parameter in the first question to answer the second question.  -->
<!-- -- 6.4.2.2: Preceptor Table: Explain/Create the preceptor table.  -->
<!-- - 6.4.3: Justice: -->
<!-- -- 6.4.3.1: Binomial model: Present binomial equation as the basis for our future models.  -->
<!-- -- 6.4.3.2: Examining validiity: Does phat represent p? Is our data good? -->
<!-- - 6.4.4: Courage: -->
<!-- -- 6.4.4.1: From discrete to continuous: Explain that we no longer know how many beads in the urn, so we will create alot of p values and do 1,000 samples for each one to find the most common probibility for each number of beads.  -->
<!-- -- 6.4.4.2: Joint distribution: Create the joint distribution. Also include rayshader plots.  -->
<!-- -- 6.4.4.3: Hypothesis testing: Explain that hypothesis testing is bad, and that instead we should create a distribution that displays the range of possible outcomes instead of simply disproving one possible outcome.  -->
<!-- -- 6.4.4.4: Posterior Distribution: Explain taking a  -->
<!-- -- 6.4.4.5: Binomial Distribution: Compare bead distribution to another binomial distribution such as flipping a coin. Then convert to a probibility distribution, and calculate the answer to the second question. -->
<!-- - 6.4.5: Temperence:  -->
<!-- -- 6.4.5.1: Changing the starting data: What happens if our starting data was different? (Explore different packages that might allow readers to explore this for themselves in a cool way.) -->
<!-- - 6.4.6: stan_glm(): Introduce stan_glm() for Ch. 7. Makes everything we did above way easier.  -->
<!-- 6.5 The Real World -->
<!-- -Notes: Will be mostly the same as current section. -->
<!-- Questions: Use annual family survey (3000 people) instead of kennedy study? This provides an actual dataset we can work with. Introduce the vocab and write up in the primer, and then dive into the dataset in the tutorials. Data set has collumn for "are you married" which allows us to estimate a population proportion, but it also has other data that can allow us to calculate the population mu within a certain confidence interval if we know sigma, but this might be too much. However, I do think it is important to differentiate finding a population mu vs population proportion. Also should I incorporate this into the existing tutorial or make a new tutorial? -->
<!-- - 6.5.1: Kennedy Study: Exact same as current 6.5.2. Compare population, sampling, population params, etc. between Kennedy Study and Bead example.  -->
<!-- - 6.5.2: Experimental Design: This would be new. Discuss basic experimental design and bias. What are some warning signs for bad design? Is the Kennedy Obama Study biased? How about the bead examples? How do we acheive good experimental design. This section would be a brief introduction to topics discussed in an intro stats class.  -->
<!-- -- Add  El Jefe's or Felipe's to this section.  -->
<!-- - 6.5.3: Variance: Talk about standard error in real world, compared to the bead example. Maybe also discuss confidence intervals, and accuracy/precision.  -->
<!-- 6.7 Summary -->
<!-- Old stuff: -->
<!-- Another paragraph or two of discussion about the final posterior. How do we use it? Within what range would you offer 50/50 odds that the true percentage lies? (use quantile(0.25, 0.75). Area under the curve? Explain clearly how that 26% is calculated. What is post_dist? What does it mean? How can I use it? Maybe show it sorted? Add some code comments. -->
<!-- Expand the use of rayshader. For each 3-D graphic, we need to add a movie with five frames. First frame is the current graphic. Second frame is with the conditional distribution set as a different color, probably red. We want to see this slice in the context of the joint distribution. Third frame shows the joint distribution with all non-red points going to zero. Ideally, this would be in motion, with the points just decreasing down. The meaning is that taking a conditional distribution means that everything outside that slice goes to zero. They are impossible. Fourth frame shows us rotate around so that we are looking at the cross-section from the side. -->
<!-- You must understand what the standard error of $\hat{\rho}$ means. You do not need to understand why. -->
<!-- In the Functions are your friend! section -->
<!-- The variation in p-hat (when we do 1,000 reps) decreases as shovel size increases. For each shovel size, you plot 1,000 points. Small shovels have lots of overlap, so, use alpha. Even big shovels only have scores of possible p-hats. Then, say, can we measure the decrease in varition more precisely then just looking at this cloud of points? Yes! Plot the standard deviation of the cloud for each shovel size. -->
<!-- RS: Graph 1,000 points of phat? Woudn't this be misleading, because of like what is said above, that small shovels only have a few possible models?-->
<!-- Maybe make it a gganimation? -->
<!-- Explain in a comment the reason for  fun = function(.x) 1/(2 * sqrt(.x)) in the plot. I don't know why we need the 2. We would probably use geom_function(). Maybe using geom_function with the function for a standard error will just magically work! -->
<!-- A paragraph about the distinction between distributions and probability distributions. We often can work with the former till the very end. When answering most questions, I can just work with the "raw" distribution. I don't need the posterior probability distribution. -->
<!-- RS: Still confused about this myself. Wouldn't we always want to end with a standardized posterior probability distribution? Standardized just seems better. -->
<!-- Could not get figure references to work. They have been removed. But we ought to figure that out and add them back!  Should create a simple example (three line Rmd file) and then ask on RStudio Community.  -->
<!-- Make a 15 second video, put it on YouTube. "We don't estimate parameters because we care about parameters. Parameters are imaginary! Like unicorns! [Put finger on forehead and imitate unicorn.] We estimate parameters to build Data Generating Mechanisms. And with a DGM, you can move the world!" -->
<p><em>This chapter is being re-drafted.</em></p>
<iframe src="https://www.youtube.com/embed/e3PJ3Du_zDc?showcase=0" width="100%" height="400px">
</iframe>
<p><em>The Hunger Games</em> is a dystopian novel in which children are chosen via lottery to fight to the death. Primrose Everdeen is selected from the urn. Why does she have the misfortune of being selected? Or, as we data scientists say, <em>sampled</em>?</p>
<p>In Chapter <a href="probability.html#probability">5</a>, we learned about probability, the framework for quantifying uncertainty. In this chapter, we will learn about <em>sampling</em>, the beginning of our journey toward inference. When we sample, we take some <em>units</em> from a <em>population</em>, calculate statistics based on those units, and make inferences about unknown <em>parameters</em> associated with the population.</p>
<p>The urn below has a certain number of red and a certain number of white beads all of equal size, mixed well together. What proportion, <span class="math inline">\(\rho\)</span>, of this urn’s beads are red?</p>
<div class="figure">
<span id="fig:unnamed-chunk-459"></span>
<img src="06-one-parameter/images/sampling_bowl_1.jpg" alt="An urn with red and white beads." width="100%"><p class="caption">
FIGURE 6.1: An urn with red and white beads.
</p>
</div>
<p>One way to answer this question would be to perform an exhaustive count: remove each bead individually, count the number of red beads, count the number of white beads, and divide the number of red beads by the total number of beads. Call that ratio <span class="math inline">\(\rho\)</span>, the proportion of red beads in the urn. However, this would be a long and tedious process. Therefore, we will use sampling! Consider two questions:</p>
<p><em>If we get 17 red beads in a random sample of size 50 taken from a mixed urn, what proportion <span class="math inline">\(\rho\)</span> of the beads in the urn are red?</em></p>
<p><em>What is the probability, using that same urn, that we will draw more than 8 red beads if we use a shovel of size 20?</em></p>
<p>To begin this chapter, we will look at a real sampling activity: the urn. Then, we will simulate the urn example using R code. This will help us to understand the <em>standard error</em> and the ways in which uncertainty factors into our predictions. We then create a joint distribution of models and data for the urn example. We derive a posterior distribution from that joint distribution, and then use that posterior to answer our questions.</p>
<!-- RS: Add foreshadowing to Ch. 7, saying something like: "To try and estimate the probability distribution of a single parameter, p." Ch.7 does a good job of explaining 1 param v. 2 params, but readers should know what they are getting into. (Include this when we get into "answering the questions")-->
<p>Use the <strong>tidyverse</strong> package.</p>
<div class="sourceCode" id="cb649"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></code></pre></div>
<div id="sampling-activity" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Real sampling activity<a class="anchor" aria-label="anchor" href="#sampling-activity"><i class="fas fa-link"></i></a>
</h2>
<div class="figure">
<span id="fig:unnamed-chunk-461"></span>
<img src="06-one-parameter/images/sampling_bowl_1.jpg" alt="An urn with red and white beads." width="100%"><p class="caption">
FIGURE 6.2: An urn with red and white beads.
</p>
</div>
<div id="using-the-shovel-method-once" class="section level3" number="6.1.1">
<h3>
<span class="header-section-number">6.1.1</span> Using the shovel method once<a class="anchor" aria-label="anchor" href="#using-the-shovel-method-once"><i class="fas fa-link"></i></a>
</h3>
<p>Instead of performing an exhaustive count, let’s insert a shovel into the urn and remove <span class="math inline">\(5 \cdot 10 = 50\)</span> beads. We are taking a <em>sample</em> of the total population of beads.</p>
<div class="figure">
<span id="fig:unnamed-chunk-462"></span>
<img src="06-one-parameter/images/sampling_bowl_2.jpg" alt="Inserting a shovel into the urn." width="100%"><p class="caption">
FIGURE 6.3: Inserting a shovel into the urn.
</p>
</div>
<div class="figure">
<span id="fig:unnamed-chunk-463"></span>
<img src="06-one-parameter/images/sampling_bowl_3_cropped.jpg" alt="Removing 50 beads from the urn." width="100%"><p class="caption">
FIGURE 6.4: Removing 50 beads from the urn.
</p>
</div>
<p>Observe that 17 of the 50 sampled beads are red and thus <span class="math inline">\(17/50 = 0.34 = 34\%\)</span> of the shovel’s beads are red. We can view the proportion of beads that are red in this shovel as a guess of the proportion of beads that are red in the entire urn. While not as exact as doing an exhaustive count of all the beads in the urn, our guess of 34% took much less time and energy to make.</p>
<p>Recall that <span class="math inline">\(\rho\)</span> is the true value of the proportion of red beads. There is only one <span class="math inline">\(\rho\)</span>. Our guesses at the proportion of red beads are known as <span class="math inline">\(\hat{\rho}\)</span> (pronounced p hat), where <span class="math inline">\(\hat{\rho}\)</span> is the estimated value of <span class="math inline">\(\rho\)</span> which comes from taking a sample. There are many possible <span class="math inline">\(\hat{\rho}\)</span>’s. You and I will often differ in our estimates. We each have a different <span class="math inline">\(\hat{\rho}\)</span> even though we agree that there is only one <span class="math inline">\(\rho\)</span>.</p>
<p>Start this activity over from the beginning, placing the 50 beads back into the urn. Would a second sample include exactly 17 red beads? Maybe, but probably not.</p>
<p>What if we repeated this activity <em>many</em> times? Would our guess at the proportion of the urn’s beads that are red, <span class="math inline">\(\hat{\rho}\)</span>, be exactly 34% every time? Surely not.</p>
<p>Let’s repeat this exercise with the help of 33 groups of friends to understand how the value of <span class="math inline">\(\hat{\rho}\)</span> varies across 33 independent trials.</p>
</div>
<div id="student-shovels" class="section level3" number="6.1.2">
<h3>
<span class="header-section-number">6.1.2</span> Using the shovel 33 times<a class="anchor" aria-label="anchor" href="#student-shovels"><i class="fas fa-link"></i></a>
</h3>
<p>Each of our 33 groups of friends will do the following:</p>
<ul>
<li>Use the shovel to remove 50 beads each.</li>
<li>Count the number of red beads and compute the proportion of the 50 beads that are red.</li>
<li>Return the beads into the urn.</li>
<li>Mix the contents of the urn to not let a previous group’s results influence the next group’s.</li>
</ul>
<p>Each of our 33 groups of friends make note of their proportion of red beads from their sample collected. Each group then marks their proportion of their 50 beads that were red in the appropriate bin in a hand-drawn histogram as seen below.</p>
<div class="figure">
<span id="fig:unnamed-chunk-464"></span>
<img src="06-one-parameter/images/tactile_3_a.jpg" alt="Constructing a histogram of proportions." width="100%"><p class="caption">
FIGURE 6.5: Constructing a histogram of proportions.
</p>
</div>
<p>Histograms allow us to visualize the <em>distribution</em> of a numerical variable. In particular, where the center of the values falls and how the values vary. A partially completed histogram of the first 10 out of 33 groups of friends’ results can be seen in the figure below.</p>
<div class="figure">
<span id="fig:unnamed-chunk-465"></span>
<img src="06-one-parameter/images/tactile_3_c.jpg" alt="Hand-drawn histogram of first 10 out of 33 proportions." width="100%"><p class="caption">
FIGURE 6.6: Hand-drawn histogram of first 10 out of 33 proportions.
</p>
</div>
<p>Observe the following details in the histogram:</p>
<ul>
<li>At the low end, one group removed 50 beads from the urn with proportion red between 0.20 and 0.25.</li>
<li>At the high end, another group removed 50 beads from the urn with proportion between 0.45 and 0.5 red.</li>
<li>However, the most frequently occurring proportions were between 0.30 and 0.35 red, right in the middle of the distribution.</li>
<li>The distribution is somewhat bell-shaped.</li>
</ul>
<p><code>tactile_sample_urn</code> saves the results from our 33 groups of friends.</p>
<pre><code>## # A tibble: 33 x 4
##    group         red_beads prop_red group_ID
##    &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;
##  1 Mal, Francis         17     0.34        1
##  2 Nam, Joshua          19     0.38        2
##  3 Mark, Ramses         21     0.42        3
##  4 Maeve, Josh          18     0.36        4
##  5 Morgan, Emily        21     0.42        5
##  6 Ace, Chris           18     0.36        6
##  7 Mia, James           15     0.3         7
##  8 Griffin, Mary        18     0.36        8
##  9 Yuki, Harry          21     0.42        9
## 10 Frank, Clara         21     0.42       10
## # … with 23 more rows</code></pre>
<p>For each <code>group</code>, we are given their names, the number of <code>red_beads</code> they obtained, and the corresponding proportion out of 50 beads that were red, called <code>prop_red</code>. We also have an <code>group_ID</code> variable which gives each of the 33 groups a unique identifier. Each row can be viewed as one instance of a replicated activity: using the shovel to remove 50 beads and computing the proportion of those beads that are red.</p>
<p>Let’s visualize the distribution of these 33 proportions using <code>geom_histogram()</code> with <code>binwidth = 0.05</code>. This is a computerized and complete version of the partially completed hand-drawn histogram you saw earlier. Setting <code>boundary = 0.4</code> indicates that we want a binning scheme such that one of the bins’ boundary is at 0.4. <code>color = "white"</code> modifies the color of the boundary for visual clarity.</p>
<div class="sourceCode" id="cb651"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tactile_sample_urn</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.05</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  
  <span class="co"># Add scale_y_continuous with breaks by 1, as the default shows the y-axis</span>
  <span class="co"># from 1 to 10 with breaks at .5. Breaks by 1 is better for this plot, as all</span>
  <span class="co"># resulting values are integers.</span>
  
  <span class="fu">scale_y_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  
  <span class="co"># The call expression() is used to insert a mathematical expression, like</span>
  <span class="co"># p-hat. The paste after expression allows us to paste text prior to said</span>
  <span class="co"># expression.</span>
  
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Proportion of 50 beads that were red "</span>, <span class="fu"><a href="https://rdrr.io/r/grDevices/plotmath.html">hat</a></span><span class="op">(</span><span class="va">rho</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
       y <span class="op">=</span> <span class="st">"Count"</span>,
       title <span class="op">=</span> <span class="st">"Proportions Red in 33 Samples"</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-467-1.png" width="100%"></div>
</div>
<div id="what-did-we-just-do" class="section level3" number="6.1.3">
<h3>
<span class="header-section-number">6.1.3</span> What did we just do?<a class="anchor" aria-label="anchor" href="#what-did-we-just-do"><i class="fas fa-link"></i></a>
</h3>
<p>What we just demonstrated in this activity is the statistical concept of <strong>sampling</strong>. We want to know the proportion of red beads in the urn, with the urn being our <strong>population</strong>. Performing an exhaustive count of the red and white beads would be too time-consuming. Therefore, it is much more practical to extract a <em>sample</em> of 50 beads using the shovel. Using this sample of 50 beads, we estimated the proportion of the urn’s beads that are red to be about 34%.</p>
<p>Moreover, because we mixed the beads before each use of the shovel, the samples were random and independent. Because each sample was drawn at random, the samples were different from each other. This is an example of <em>sampling variation</em>. For example, what if instead of selecting 17 beads in our first sample we had selected just 11? Does that mean that the population proportion of the beads is 11/50 or 22%? No! Because we performed 33 trials we can look to our histogram, and see that the peak of the distribution occurs when <span class="math inline">\(.35 &lt; \hat{\rho} &lt; .4\)</span> , so it is <em>very likely</em> that the proportion of red beads in the entire population will also fall in or near this range.</p>
</div>
</div>
<div id="virtual-sampling" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Virtual sampling<a class="anchor" aria-label="anchor" href="#virtual-sampling"><i class="fas fa-link"></i></a>
</h2>
<p>We just performed a <em>tactile</em> sampling activity. We used a physical urn of beads and a physical shovel. We did this by hand so that we could develop our intuition about the ideas behind sampling. In this section, we mimic this physical sampling with <em>virtual</em> sampling, using a computer.</p>
<div id="shovel-one-time" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> Using the virtual shovel once<a class="anchor" aria-label="anchor" href="#shovel-one-time"><i class="fas fa-link"></i></a>
</h3>
<p>Virtual sampling requires a virtual urn and a virtual shovel. Create a tibble named <code>urn</code>. The rows of <code>urn</code> correspond exactly to the contents of the actual urn.</p>
<div class="sourceCode" id="cb652"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># set.seed() ensures that the beads in our virtual urn are always in the same</span>
<span class="co"># order. This ensures that the figures in the book match their written</span>
<span class="co"># descriptions. We want 40% of the beads to be red.</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>

<span class="va">urn</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="fl">400</span><span class="op">)</span>, 
                        <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"white"</span>, <span class="fl">600</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  
  <span class="co"># sample_frac() keeps all the rows in the tibble but rearranges their order.</span>
  <span class="co"># We don't need to do this. A virtual urn does not care about the order of the</span>
  <span class="co"># beads. But we find it aesthetically pleasing to mix them up.</span>
  
  <span class="fu">sample_frac</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bead_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> 

<span class="va">urn</span>  </code></pre></div>
<pre><code>## # A tibble: 1,000 x 2
##    color bead_ID
##    &lt;chr&gt;   &lt;int&gt;
##  1 white       1
##  2 white       2
##  3 red         3
##  4 red         4
##  5 white       5
##  6 white       6
##  7 white       7
##  8 white       8
##  9 white       9
## 10 white      10
## # … with 990 more rows</code></pre>
<p>Observe that <code>urn</code> has 1,000 rows, meaning that the urn contains
1,000 beads. The first variable <code>bead_ID</code> is used as an <em>identification variable</em>. None of the beads in the actual urn are marked with numbers. The second variable <code>color</code> indicates whether a particular virtual bead is red or white.</p>
<p>Note that in this section, we used the variable <code>bead_ID</code> to keep track of each bead in our urn, while in the last section we used <code>group_ID</code> to keep track of the samples drawn by the 33 individual teams. This is a better strategy than naming both variables <code>ID</code>, as it would be much more likely for us to get them confused later on.</p>
<p>Our virtual urn needs a virtual shovel. We use <code>slice_sample()</code> and list-column mapping wizardry learned in Section <a href="probability.html#list-columns-and-map-functions">5.1</a> to take a sample of 50 beads from our virtual urn.</p>
<div class="sourceCode" id="cb654"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Define trial_ID as one instance of us sampling 50 beads from the urn. When</span>
<span class="co"># trial_ID is called within map(), we are performing slice_sample() upon our urn</span>
<span class="co"># once, and taking a sample of 50 beads. </span>

<span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   trial_ID shovel           
##      &lt;dbl&gt; &lt;list&gt;           
## 1        1 &lt;tibble [50 × 2]&gt;</code></pre>
<p>As usual, map functions and list-columns are powerful but confusing. The <code><a href="https://rdrr.io/r/utils/str.html">str()</a></code> function is a good way to explore a tibble with a list-column.</p>
<div class="sourceCode" id="cb656"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## tibble [1 × 2] (S3: tbl_df/tbl/data.frame)
##  $ trial_ID: num 1
##  $ shovel  :List of 1
##   ..$ : tibble [50 × 2] (S3: tbl_df/tbl/data.frame)
##   .. ..$ color  : chr [1:50] "white" "white" "white" "red" ...
##   .. ..$ bead_ID: int [1:50] 812 903 227 283 229 160 523 893 66 277 ...</code></pre>
<p>There are two levels. There is one row in the tibble for each sample. So far, we have only drawn one sample. Within each row, there is a second level, the tibble which is the sample. That tibble has two variables: <code>trial_ID</code> and <code>color</code>. This is the advantage to using <code>slice_sample()</code>, because it selects all columns of our urn, whereas <code><a href="https://rdrr.io/r/base/sample.html">sample()</a></code> can only sample from a single column. While identifying each individual bead could be irrelevant in our urn scenario, with other problems it could be very useful to have additional data about each individual.</p>
<p>However, it is important to note that the extra data provided by <code>slice_sample()</code> comes at a cost: <em>efficiency</em>. Because most of us run R Studio on our local machines, each R variable is stored using memory on our computers. As we add more columns or more complex objects to our tibbles, they will take up more memory and become less efficient. For example, <code>slice_sample()</code> will store a tibble for each sample, while <code><a href="https://rdrr.io/r/base/sample.html">sample()</a></code> will store a list. And the difference is not negligible! We can use the handy utility function <code><a href="https://rdrr.io/r/utils/object.size.html">object.size()</a></code> to know an empty tibble takes up 736 bytes of memory, while an empty list takes up no memory. While our urn simulation takes up a relatively small amount of storage and we are not overly concerned with optimizing tibble size, it never hurts to practice making our tibbles more efficient. Before working with large data sets that may take several minutes to load, it may be helpful to read this <a href="http://adv-r.had.co.nz/memory.html">article about memory in R</a> to make sure we understand the implications of using complex datatypes within tibbles, so we can make the most out of our future list-column mapping endeavors.</p>
<p>Now that we’ve evaluated the implications of <code>slice_sample()</code> for our tibble, let’s add a column which indicates the number of red beads in the sample taken from the shovel.</p>
<!-- DK: Is code like .$color understandable? -->
<!-- RS: I think the dollar sign operator should be understood at this point, but was thinking about asking Yuhan to include a way better explanation about the "this" operator in Chapter 5.  -->
<div class="sourceCode" id="cb658"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  
<span class="co"># To count the number of red beads in each shovel, we can use a lesser </span>
<span class="co"># known property of the sum() function: By passing in a comparison </span>
<span class="co"># expression, sum() will count the number of occurrences within a vector. </span>
<span class="co"># In this case, we count the total number occurrences of the word red</span>
<span class="co"># in the color column of shovel.</span>

  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   trial_ID shovel            numb_red
##      &lt;dbl&gt; &lt;list&gt;               &lt;int&gt;
## 1        1 &lt;tibble [50 × 2]&gt;       20</code></pre>
<p>How does this work? R evaluates if <code>color == red</code>, and treats <code>TRUE</code> values like the number <code>1</code> and <code>FALSE</code> values like the number <code>0</code>. So summing the number of <code>TRUE</code>s and <code>FALSE</code>s is equivalent to summing <code>1</code>’s and <code>0</code>’s. In the end, this operation counts the number of beads where <code>color</code> equals “red.”</p>
<p>Finally, calculate the proportion red by dividing <code>numb_red</code> (The number of red beads observed in the shovel), by the shovel size (We are using a shovel of size 50).</p>
<div class="sourceCode" id="cb660"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="fl">50</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##   trial_ID shovel            numb_red prop_red
##      &lt;dbl&gt; &lt;list&gt;               &lt;int&gt;    &lt;dbl&gt;
## 1        1 &lt;tibble [50 × 2]&gt;       23     0.46</code></pre>
<p>Careful readers will note that the <code>numb_red</code> is changing in each example above. The reason, of course, is that each block re-runs the shovel exercise, and slice_sample will return a random number of red beads. If we wanted the same number in each block, we would need to use <code><a href="https://rdrr.io/r/base/Random.html">set.seed()</a></code> each time, always providing the same <code>seed</code> each time.</p>
<p>Let’s now perform the virtual analog of having 33 groups of students use the sampling shovel!</p>
</div>
<div id="shovel-33-times" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> Using the virtual shovel 33 times<a class="anchor" aria-label="anchor" href="#shovel-33-times"><i class="fas fa-link"></i></a>
</h3>
<p>In our tactile sampling exercise in Section <a href="one-parameter.html#sampling-activity">6.1</a>, we had 33 groups of students use the shovel, yielding 33 samples of size 50 beads. We then used these 33 samples to compute 33 proportions.</p>
<p>Let’s use our virtual sampling to replicate the tactile sampling activity in a virtual format. We’ll save these results in a data frame called <code>virtual_samples</code>.</p>
<div class="sourceCode" id="cb662"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">9</span><span class="op">)</span>

 <span class="va">virtual_samples</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">33</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="fl">50</span><span class="op">)</span> 

<span class="va">virtual_samples</span></code></pre></div>
<pre><code>## # A tibble: 33 x 4
##    trial_ID shovel            numb_red prop_red
##       &lt;int&gt; &lt;list&gt;               &lt;int&gt;    &lt;dbl&gt;
##  1        1 &lt;tibble [50 × 2]&gt;       21     0.42
##  2        2 &lt;tibble [50 × 2]&gt;       19     0.38
##  3        3 &lt;tibble [50 × 2]&gt;       17     0.34
##  4        4 &lt;tibble [50 × 2]&gt;       15     0.3 
##  5        5 &lt;tibble [50 × 2]&gt;       17     0.34
##  6        6 &lt;tibble [50 × 2]&gt;       21     0.42
##  7        7 &lt;tibble [50 × 2]&gt;        9     0.18
##  8        8 &lt;tibble [50 × 2]&gt;       21     0.42
##  9        9 &lt;tibble [50 × 2]&gt;       16     0.32
## 10       10 &lt;tibble [50 × 2]&gt;       20     0.4 
## # … with 23 more rows</code></pre>
<p>Let’s visualize this variation in a histogram:</p>
<div class="sourceCode" id="cb664"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">virtual_samples</span> <span class="op">%&gt;%</span> 
<span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.05</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  
  <span class="co"># To use mathematical symbols in titles and labels, use the expression()</span>
  <span class="co"># function, as here.</span>
  
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/plotmath.html">hat</a></span><span class="op">(</span><span class="va">rho</span><span class="op">)</span><span class="op">)</span>,
       y <span class="op">=</span> <span class="st">"Count"</span>,
       title <span class="op">=</span> <span class="st">"Distribution of 33 proportions red"</span><span class="op">)</span> <span class="op">+</span>
  
  <span class="co"># Label the y-axis in an attractive fashion. Without this code, the axis</span>
  <span class="co"># labels would include 2.5, which makes no sense because all the values are</span>
  <span class="co"># integers.</span>
  
  <span class="fu">scale_y_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-474-1.png" width="100%"></div>
<p>Since <code>binwidth = 0.05</code>, this will create bins with boundaries at 0.30, 0.35, 0.45, and so on. Recall that <span class="math inline">\(\hat{\rho}\)</span> is equal to the proportion of beads which are red in each sample.</p>
<p>Observe that we occasionally obtained proportions red that are less than 30%. On the other hand, we occasionally obtained proportions that are greater than 45%. However, the most frequently occurring proportions were between 35% and 45%. Why do we have these differences in proportions red? Because of <em>sampling variation</em>.</p>
<p>Now we will compare our virtual results with our tactile results from the previous section. Observe that both histograms are somewhat similar in their center and variation, although not identical. These slight differences are again due to random sampling variation. Furthermore, observe that both distributions are somewhat bell-shaped.</p>
<div class="figure">
<span id="fig:unnamed-chunk-475"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-475-1.png" alt="Comparing 33 virtual and 33 tactile proportions red. Note that, though the figures differ slightly, both are centered around .35 to .45. This shows that, in both sampling distributions, the most frequently occuring proportion red is between 35% and 45%." width="100%"><p class="caption">
FIGURE 6.7: Comparing 33 virtual and 33 tactile proportions red. Note that, though the figures differ slightly, both are centered around .35 to .45. This shows that, in both sampling distributions, the most frequently occuring proportion red is between 35% and 45%.
</p>
</div>
<p>This visualization allows us to see how our results differed between our tactile and virtual urn results. As we can see, there is some variation between our results. This is not a cause for concern, as there is always expected sampling variation between results.</p>
</div>
<div id="shovel-1000-times" class="section level3" number="6.2.3">
<h3>
<span class="header-section-number">6.2.3</span> Using the virtual shovel 1,000 times<a class="anchor" aria-label="anchor" href="#shovel-1000-times"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-476"></span>
<img src="06-one-parameter/images/sample_bernie.png" alt="So much sampling, so little time." width="100%"><p class="caption">
FIGURE 6.8: So much sampling, so little time.
</p>
</div>
<p>Although we took 33 samples from the urn in the previous section, we should never do that again! The advantage of modern technology is that we can use virtual simulation as many times as we choose, so we have no restrictions on resources. No longer are the days where we have to recruit our friends to tirelessly sample from the physical urn. We are now data scientists! 33 samples are useless to us. Instead, we use our simulations hundreds or thousands of times to create mathematical models that we can combine with our knowledge to answer our questions. In this section we’ll examine the effects of sampling from the urn 1,000 times.</p>
<p>We can reuse our code from above, making sure to replace 33 trials with 1,000.</p>
<div class="sourceCode" id="cb665"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">9</span><span class="op">)</span>

 <span class="va">virtual_samples</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_beads <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="va">numb_beads</span><span class="op">)</span> </code></pre></div>
<p>Now we have 1,000 values for <code>prop_red</code>, each representing the proportion of 50 beads that are red in a sample. Using the same code as earlier, let’s visualize the distribution of these 1,000 replicates of <code>prop_red</code> in a histogram:</p>
<div class="sourceCode" id="cb666"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">virtual_samples</span> <span class="op">%&gt;%</span> 
<span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.01</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/plotmath.html">hat</a></span><span class="op">(</span><span class="va">rho</span><span class="op">)</span><span class="op">)</span>,
       y <span class="op">=</span> <span class="st">"Count"</span>,
       title <span class="op">=</span> <span class="st">"Distribution of 1,000 proportions red"</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-478-1.png" width="100%"></div>
<p>Why the empty spaces among the bars? Recall that, with only 50 beads, there are only 51 possible values for <span class="math inline">\(\hat{\rho}\)</span>: 0, 0.02, 0.04, …, 0.98, 1. A value of 0.31 or 0.47 is impossible, hence the gaps.</p>
<p>The most frequently occurring proportions of red beads occur, again, between 35% and 45%. Every now and then we observe proportions much higher or lower. This occurs because as we increase the number of trials, tails develop on our distribution as we are more likely to witness extreme <span class="math inline">\(\hat{\rho}\)</span> values. The symmetric, bell-shaped distribution shown in the histogram is well approximated by the <em>normal distribution</em>.</p>
<p>Now that we have a good understanding of virtual sampling, we can apply our knowledge to examine the effects of changing our virtual shovel size.</p>
</div>
<div id="different-shovels" class="section level3" number="6.2.4">
<h3>
<span class="header-section-number">6.2.4</span> The effect of different shovel sizes<a class="anchor" aria-label="anchor" href="#different-shovels"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-479"></span>
<img src="06-one-parameter/images/three_shovels.png" alt="What happens if we use different sized shovels to sample?" width="100%"><p class="caption">
FIGURE 6.9: What happens if we use different sized shovels to sample?
</p>
</div>
<p>Instead of just one shovel, imagine we have three choices of shovels to extract a sample of beads with: shovels of size 25, 50, and 100. Using our newly developed tools for virtual sampling, let’s unpack the effect of having different sample sizes. Start by creating a tibble with 1,000 rows, each row representing an instance of us sampling from the urn with our chosen shovel size. Then, compute the resulting 1,000 replicates of proportion red. Finally, plot the distribution using a histogram.</p>
<div class="sourceCode" id="cb667"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Within slice_sample(), n = 25 represents our shovel of size 25. We also divide</span>
<span class="co"># by 25 to compute the proportion red.</span>

<span class="va">virtual_samples_25</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">25</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="fl">25</span><span class="op">)</span>

<span class="va">virtual_samples_25</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.04</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Proportion of 25 beads that were red"</span>, 
       title <span class="op">=</span> <span class="st">"25"</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-480-1.png" width="100%"></div>
<p>We will repeat this process with a shovel size of <strong>50</strong>.</p>
<div class="sourceCode" id="cb668"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">virtual_samples_50</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="fl">50</span><span class="op">)</span>


<span class="va">virtual_samples_50</span>  <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.04</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Proportion of 50 beads that were red"</span>, 
       title <span class="op">=</span> <span class="st">"50"</span><span class="op">)</span>  </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-481-1.png" width="100%"></div>
<p>We choose a bin width of .04 for all histograms to more easily compare different shovel sizes. Using a smaller bin size would result in gaps between the bars, as a shovel of size 50 has more possible <span class="math inline">\(\hat{\rho}\)</span> values than a shovel of size 25.</p>
<p>Finally, we will perform the same process with 1000 replicates to map the histogram using a shovel size of <strong>100</strong>.</p>
<div class="sourceCode" id="cb669"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">virtual_samples_100</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="fl">100</span><span class="op">)</span>


<span class="va">virtual_samples_100</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.04</span>, 
                 boundary <span class="op">=</span> <span class="fl">0.4</span>, 
                 color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Proportion of 100 beads that were red"</span>, 
       title <span class="op">=</span> <span class="st">"100"</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-482-1.png" width="100%"></div>
<p>For easy comparison, we present the three resulting histograms in a single row with matching x and y axes:</p>
<div class="sourceCode" id="cb670"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Use bind_rows to combine the data from our three saved virtual sampling</span>
<span class="co"># objects. Use mutate() in each to clarify the n as the necessary number</span>
<span class="co"># of samples taken. This makes our data easier to interpret and prevents</span>
<span class="co"># duplicate elements.</span>

<span class="va">virtual_prop</span> <span class="op">&lt;-</span> <span class="fu">bind_rows</span><span class="op">(</span><span class="va">virtual_samples_25</span> <span class="op">%&gt;%</span> 
                            <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">25</span><span class="op">)</span>, 
                          <span class="va">virtual_samples_50</span> <span class="op">%&gt;%</span> 
                            <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>, 
                          <span class="va">virtual_samples_100</span> <span class="op">%&gt;%</span> 
                            <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span>

<span class="co"># Plot our new object with the x-axis showing prop_red. Add elements binwidth,</span>
<span class="co"># boundary, and color for stylistic clarity. Use labs() to add an x-axis label</span>
<span class="co"># and title. Facet_wrap() splits the graph into multiple plots by the variable</span>
<span class="co"># (~n).</span>

<span class="va">comparing_sampling_distributions</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">virtual_prop</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">prop_red</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.04</span>, boundary <span class="op">=</span> <span class="fl">0.4</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Proportion of shovel's beads that are red"</span>, 
       title <span class="op">=</span> <span class="st">"Comparing distributions of proportions red for three different shovel sizes."</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">n</span><span class="op">)</span> 

<span class="co"># Inspect our new faceted graph. </span>

<span class="va">comparing_sampling_distributions</span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-483"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-483-1.png" alt="Comparing the distributions of proportion red for different sample sizes (25, 50, 100). The important takeaway is that our center becomes more concentrated as our sample size increases, indicating a smaller standard deviation between our guesses." width="100%"><p class="caption">
FIGURE 6.10: Comparing the distributions of proportion red for different sample sizes (25, 50, 100). The important takeaway is that our center becomes more concentrated as our sample size increases, indicating a smaller standard deviation between our guesses.
</p>
</div>
<p>Observe that as the sample size increases, the histogram becomes taller and narrower. This is because the <em>variation</em> of the proportion red for each sample decreases. Remember: A large variation means there are a wide range of values that can be achieved, while smaller variations are concentrated around a specific value.</p>
<p>Why does variation decrease as sample size increases? If we use a large sample size like 100 or 500, our sample is much more representative of the population simply because more of the population is included. As a result, the proportion red in our sample (<span class="math inline">\(\hat{\rho}\)</span>) will be closer to the population proportion (<span class="math inline">\(\rho\)</span>). On the other hand, smaller samples have much more variation because of our old friend chance. We are much more likely to have extreme samples that are not representative of our population.</p>
<p>Let’s attempt to visualize the concept of <em>variation</em> a different way. For each sample size, let’s plot the proportion red for <em>all</em> 1,000 samples. With 3 different shovel sizes, we will have 3,000 total points, with each point representing an instance of sampling from the urn with a specific shovel size.</p>
<div class="sourceCode" id="cb671"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">virtual_prop</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n</span>, y <span class="op">=</span> <span class="va">prop_red</span>, color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_jitter</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">.15</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Results of 1,000 samples for 3 different shovel sizes."</span>,
       subtitle <span class="op">=</span> <span class="st">"As shovel size increases, variation decreases."</span>,
       y <span class="op">=</span> <span class="st">"Proportion red in sample"</span>,
       color <span class="op">=</span> <span class="st">"Shovel size"</span><span class="op">)</span> <span class="op">+</span>
  <span class="co"># We do not need an x axis, because the color of the points denotes the shovel size. </span>
   <span class="fu">theme</span><span class="op">(</span>axis.title.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,
        axis.text.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,
        axis.ticks.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-484-1.png" width="100%"></div>
<p>This graph illustrates the exact same concept as the histogram. With the smallest shovel size there is significant variance from sample to sample, as samples take on a wide variety of sample proportions! However, as we increase the sample size, the points become more concentrated, or less variance.</p>
<p>There is also a third way to understand variation! We can be numerically explicit about the amount of variation in our three sets of 1,000 values of <code>prop_red</code> by using the <em>standard deviation</em>. A standard deviation is a summary statistic that measures the amount of variation within a numerical variable. For all three sample sizes, let’s compute the standard deviation of the 1,000 proportions red.</p>
<div id="ygwszswkvq" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#ygwszswkvq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ygwszswkvq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ygwszswkvq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ygwszswkvq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ygwszswkvq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ygwszswkvq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ygwszswkvq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ygwszswkvq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ygwszswkvq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ygwszswkvq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ygwszswkvq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ygwszswkvq .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ygwszswkvq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ygwszswkvq .gt_from_md > :first-child {
  margin-top: 0;
}

#ygwszswkvq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ygwszswkvq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ygwszswkvq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ygwszswkvq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ygwszswkvq .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ygwszswkvq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ygwszswkvq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ygwszswkvq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ygwszswkvq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ygwszswkvq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ygwszswkvq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ygwszswkvq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ygwszswkvq .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ygwszswkvq .gt_left {
  text-align: left;
}

#ygwszswkvq .gt_center {
  text-align: center;
}

#ygwszswkvq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ygwszswkvq .gt_font_normal {
  font-weight: normal;
}

#ygwszswkvq .gt_font_bold {
  font-weight: bold;
}

#ygwszswkvq .gt_font_italic {
  font-style: italic;
}

#ygwszswkvq .gt_super {
  font-size: 65%;
}

#ygwszswkvq .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_header"><tr>
<th colspan="2" class="gt_heading gt_title gt_font_normal gt_bottom_border" style>Comparing standard deviations of proportions red for three different shovels</th>
    </tr></thead>
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Number of slots in shovel</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Standard deviation of proportions red</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_right">25</td>
<td class="gt_row gt_right">0.099</td>
</tr>
<tr>
<td class="gt_row gt_right">50</td>
<td class="gt_row gt_right">0.067</td>
</tr>
<tr>
<td class="gt_row gt_right">100</td>
<td class="gt_row gt_right">0.045</td>
</tr>
</tbody>
</table></div>
</div>
<p> </p>
<p>As the sample size increases, the sample to sample variation decreases, and our guesses at the true proportion of the urn’s beads that are red get more precise. The larger the shovel, the more precise the result.</p>
<div class="figure">
<span id="fig:unnamed-chunk-486"></span>
<img src="06-one-parameter/images/variance_everywhere_meme.jpeg" alt="Variance appears everywhere in data science." width="100%"><p class="caption">
FIGURE 6.11: Variance appears everywhere in data science.
</p>
</div>
<p>Let’s take a step back from all the variance. The reality is that our code needs to be <em>re-factored</em>, as it is bad practice to make a separate tibble for each sample size. To make comparisons easier, let’s attempt to put all 3 shovel sizes in the same tibble using mapping.</p>
<div class="sourceCode" id="cb672"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel_ID <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">trial_ID</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">unnest</span><span class="op">(</span><span class="va">shovel_ID</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>samples <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">shovel_ID</span>, <span class="op">~</span><span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>num_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">samples</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">num_red</span><span class="op">/</span><span class="va">shovel_ID</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3,000 x 5
##    trial_ID shovel_ID samples            num_red prop_red
##       &lt;int&gt;     &lt;dbl&gt; &lt;list&gt;               &lt;int&gt;    &lt;dbl&gt;
##  1        1        25 &lt;tibble [25 × 2]&gt;       12     0.48
##  2        1        50 &lt;tibble [50 × 2]&gt;       24     0.48
##  3        1       100 &lt;tibble [100 × 2]&gt;      39     0.39
##  4        2        25 &lt;tibble [25 × 2]&gt;       13     0.52
##  5        2        50 &lt;tibble [50 × 2]&gt;       21     0.42
##  6        2       100 &lt;tibble [100 × 2]&gt;      45     0.45
##  7        3        25 &lt;tibble [25 × 2]&gt;       16     0.64
##  8        3        50 &lt;tibble [50 × 2]&gt;       26     0.52
##  9        3       100 &lt;tibble [100 × 2]&gt;      38     0.38
## 10        4        25 &lt;tibble [25 × 2]&gt;        9     0.36
## # … with 2,990 more rows</code></pre>
<p>To those of us who do not completely understand mapping, do not fret! The <strong>tidyr</strong> package provides the <code>expand_grid()</code> function as a neat alternative. We can use <code>expand_grid()</code> and a new variable, <code>shovel_size</code>, to create a tibble which will organize our results. Instead of using 1,000 trials, let’s use 3 to get a feel for the function.</p>
<div class="sourceCode" id="cb674"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">expand_grid</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span>, shovel_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 9 x 2
##   trial_ID shovel_size
##      &lt;int&gt;       &lt;dbl&gt;
## 1        1          25
## 2        1          50
## 3        1         100
## 4        2          25
## 5        2          50
## 6        2         100
## 7        3          25
## 8        3          50
## 9        3         100</code></pre>
<p>The above sets the stage for simulating three samples for each of three different shovel sizes. Similar code as above can be used.</p>
<div class="sourceCode" id="cb676"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">expand_grid</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span>, shovel_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">shovel_size</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span><span class="op">/</span><span class="va">shovel_size</span><span class="op">)</span> </code></pre></div>
<pre><code>## # A tibble: 9 x 5
##   trial_ID shovel_size shovel             numb_red prop_red
##      &lt;int&gt;       &lt;dbl&gt; &lt;list&gt;                &lt;int&gt;    &lt;dbl&gt;
## 1        1          25 &lt;tibble [25 × 2]&gt;        11     0.44
## 2        1          50 &lt;tibble [50 × 2]&gt;        16     0.32
## 3        1         100 &lt;tibble [100 × 2]&gt;       38     0.38
## 4        2          25 &lt;tibble [25 × 2]&gt;        12     0.48
## 5        2          50 &lt;tibble [50 × 2]&gt;        21     0.42
## 6        2         100 &lt;tibble [100 × 2]&gt;       37     0.37
## 7        3          25 &lt;tibble [25 × 2]&gt;        10     0.4 
## 8        3          50 &lt;tibble [50 × 2]&gt;        18     0.36
## 9        3         100 &lt;tibble [100 × 2]&gt;       53     0.53</code></pre>
<p>Again, we changed the second line to use <code>shovel_size</code> rather than <code>trial_ID</code> as the mapping variable since we can no longer hard code the shovel size into the call to <code>slice_sample()</code>. Expand to 1,000 simulations for each value of <code>shovel_size</code> and finish with a calculation of standard deviation.</p>
<div class="sourceCode" id="cb678"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">expand_grid</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span>, shovel_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">shovel_size</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span><span class="op">/</span><span class="va">shovel_size</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">shovel_size</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>st_dev_p_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">prop_red</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   shovel_size st_dev_p_hat
##         &lt;dbl&gt;        &lt;dbl&gt;
## 1          25       0.0975
## 2          50       0.0680
## 3         100       0.0452</code></pre>
<p>This is, approximately, the same result as we saw above, but with 1 re-factored tibble instead of 3 separate ones. We can also functions like <code>expand_grid()</code> in the future to make our code more concise.</p>
<p>Now that we have this framework, there’s no need to limit ourselves to the sizes 25, 50, and 100. Why not try all integers from 1 to 100? We can use the same code, except we’ll now set <code>shovel_size = 1:100</code>.</p>
<div class="sourceCode" id="cb680"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">shovels_100</span> <span class="op">&lt;-</span> <span class="fu">expand_grid</span><span class="op">(</span>trial_ID <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span>, shovel_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>shovel <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">shovel_size</span>, <span class="op">~</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">urn</span>, n <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>numb_red <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">shovel</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">$</span><span class="va">color</span> <span class="op">==</span> <span class="st">"red"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>prop_red <span class="op">=</span> <span class="va">numb_red</span> <span class="op">/</span> <span class="va">shovel_size</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">shovel_size</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>st_dev_p_hat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">prop_red</span><span class="op">)</span><span class="op">)</span>

<span class="fu">glimpse</span><span class="op">(</span><span class="va">shovels_100</span><span class="op">)</span></code></pre></div>
<pre><code>## Rows: 100
## Columns: 2
## $ shovel_size  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
## $ st_dev_p_hat &lt;dbl&gt; 0.490, 0.338, 0.289, 0.248, 0.210, 0.208, 0.182, 0.171, 0…</code></pre>
<p>Now, we have the standard deviation of <code>prop_red</code> for all shovel sizes from 1 to 100. Let’s plot that value to see how it changes as the shovel gets larger:</p>
<div class="figure">
<span id="fig:unnamed-chunk-493"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-493-1.png" alt="Comparing standard deviations of proportions red for 100 different shovels. The standard deviation decreases at the same rate as the square root of shovel size. The red line shows the standard error." width="100%"><p class="caption">
FIGURE 6.12: Comparing standard deviations of proportions red for 100 different shovels. The standard deviation decreases at the same rate as the square root of shovel size. The red line shows the standard error.
</p>
</div>
<p>The red line here represents an important statistical concept: standard error (SE). As the shovel size increases, and thus our sample size increases, we find that the standard error decreases. If this is confusing right now, fear not! We will delve into the explanation of standard error in our next section.</p>
<!-- The variation in p-hat (when we do 1,000 reps) decreases as shovel size increases. For each shovel size, you plot 1,000 points. Small shovels have lots of overlap, so, use alpha. Even big shovels only have scores of possible p-hats. Then, say, can we measure the decrease in varition more precisely then just looking at this cloud of points? Yes! Plot the standard deviation of the cloud for each shovel size. Done I think.-->
<div class="figure">
<span id="fig:unnamed-chunk-494"></span>
<img src="06-one-parameter/images/meme_math.png" alt="To any poets and philosophers confused about this: don't worry! It won't be on a problem set." width="100%"><p class="caption">
FIGURE 6.13: To any poets and philosophers confused about this: don’t worry! It won’t be on a problem set.
</p>
</div>
<p>This is the power of running many analyses at once using map functions and list columns: before, we could tell that the standard deviation was decreasing as the shovel size increased, but when only looking at shovel sizes of 25, 50, and 100, it wasn’t clear <em>how quickly</em> it was decreasing.</p>
</div>
</div>
<div id="standard-errors" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Standard error<a class="anchor" aria-label="anchor" href="#standard-errors"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-495"></span>
<img src="06-one-parameter/images/old_man_SE.png" alt="Standard errors are just the way old people talk about confidence intervals." width="100%"><p class="caption">
FIGURE 6.14: Standard errors are just the way old people talk about confidence intervals.
</p>
</div>
<p><em>Standard errors (SE) quantify the effect of sampling variation on our estimates.</em> In other words, they quantify how much we can expect the calculated proportions of a shovel’s beads that are red <em>to vary</em> from one sample to another sample to another sample, and so on. As a general rule, as sample size increases, the standard error decreases.</p>
<p><em>The standard error is the standard deviation of a sample statistic (aka point estimate), such as the proportion.</em> For example, the <em>standard error of the mean</em> refers to the standard deviation of the distribution of sample means taken from a population.</p>
<p>The relationship between the standard error and the standard deviation is that, for a given sample size, <em>the standard error equals the standard deviation divided by the square root of the sample size</em>. Accordingly, the standard error is inversely proportional to the sample size. The larger the sample size, the smaller the standard error.</p>
<p>If this sounds confusing, don’t worry! It is. Before we can explain this in more depth, it is important to understand some terminology.</p>
<div id="terminology-and-notation" class="section level3" number="6.3.1">
<h3>
<span class="header-section-number">6.3.1</span> Terminology and notation<a class="anchor" aria-label="anchor" href="#terminology-and-notation"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-496"></span>
<img src="06-one-parameter/images/yoda.png" alt="Let Yoda's wisdom dull the pain of this terminology section." width="100%"><p class="caption">
FIGURE 6.15: Let Yoda’s wisdom dull the pain of this terminology section.
</p>
</div>
<p>All of the concepts underlying this terminology, notation, and definitions tie directly to the concepts underlying our tactile and virtual sampling activities. It will simply take time and practice to master them.</p>
<p>First, a <strong>population</strong> is the set of relevant units. The population’s size is upper-case <span class="math inline">\(N\)</span>. In our sampling activities, the population is the collection of <span class="math inline">\(N\)</span> = 1,000 identically sized red and white beads in the urn. This is about the simplest possible population. Other examples are all the adult men in the US, all the classrooms in a school, all the wheelbarrows in Massachusetts, all the values of your blood pressure, read at five minute intervals, for your entire life. Often, the population is extends over time, as with your blood pressure readings and is, therefore, more amorphous. Consider all the people who have run for governor of a US state since 1900, or all the people who will run for governor through 2050. Those are also populations.</p>
<p>Second, a <strong>population parameter</strong> is a numerical summary quantity about the population that is unknown, but you wish you knew. For example, when this quantity is the mean, the population parameter of interest is the <em>population mean</em>. This is mathematically denoted with the Greek letter <span class="math inline">\(\mu\)</span> pronounced “mu.” In our earlier sampling from the urn activity, however, since we were interested in the <em>proportion</em> of the urn’s beads that were red, the population parameter is the <em>population proportion</em>, denoted with <span class="math inline">\(\rho\)</span>.</p>
<p>Third, a <strong>census</strong> is an exhaustive enumeration or counting of all <span class="math inline">\(N\)</span> units in the population in order to compute the population parameter’s value <em>exactly</em>. In our sampling activity, this would correspond to counting the number of beads out of <span class="math inline">\(N = 1000\)</span> that are red and computing the <em>population proportion</em> <span class="math inline">\(\rho\)</span> that are red <em>exactly</em>. When the number <span class="math inline">\(N\)</span> of individuals or observations in our population is large as was the case with our urn, a census can be quite expensive in terms of time, energy, and money. A census is impossible for any populations which includes the future, like our blood pressure next year or candidates for governor in 2040. There is a <em>truth</em> but we could not, even in theory, calculate it.</p>
<p>Fourth, <strong>sampling</strong> is the act of collecting a sample from the population when we can not, or do not want to, perform a census. The sample size is lower case <span class="math inline">\(n\)</span>, as opposed to upper case <span class="math inline">\(N\)</span> for the population’s size. Typically the sample size <span class="math inline">\(n\)</span> is much smaller than the population size <span class="math inline">\(N\)</span>. In our sampling activities, we used shovels with varying slots to extract samples of size <span class="math inline">\(n\)</span> = 1 through <span class="math inline">\(n\)</span> = 100.</p>
<p>Fifth, a <strong>point estimate</strong>, also known as a <strong>sample statistic</strong>, is a measure computed from a sample that <em>estimates</em> an unknown population parameter. In our sampling activities, recall that the unknown population parameter was the proportion of red beads and that this is mathematically denoted with <span class="math inline">\(\rho\)</span>. Our point estimate is the <em>sample proportion</em>: the proportion of the shovel’s beads that are red. In other words, it is our guess at the proportion of the urn’s beads that are red. The point estimate of the parameter <span class="math inline">\(\rho\)</span> is <span class="math inline">\(\hat{\rho}\)</span>. The “hat” on top of the <span class="math inline">\(\rho\)</span> indicates that it is an estimate of the unknown population proportion <span class="math inline">\(\rho\)</span>.</p>
<!-- RS: consider moving last 4 definitions to end discussion about sampling mechanisms, and first 4 definitions to the very start of the chapter. This vocab (with exception of point statistics) doesn't really have a purpose here, and should be used in a section where the words are actually used.  -->
<p>Sixth, a sample is said to be <strong>representative</strong> if it roughly <em>looks like</em> the population. In other words, are the sample’s characteristics a good representation of the population’s characteristics? In our sampling activity, are the samples of <span class="math inline">\(n\)</span> beads extracted using our shovels representative of the urn’s <span class="math inline">\(N\)</span> = 1000 beads?</p>
<p>Seventh, a sample is <strong>generalizable</strong> if any results based on the sample can generalize to the population. In our sampling activity, can we generalize the sample proportion from our shovels to the entire urn? Using our mathematical notation, this is akin to asking if <span class="math inline">\(\hat{\rho}\)</span> is a “good guess” of <span class="math inline">\(\rho\)</span>?</p>
<p>Eighth, <strong>biased sampling</strong> occurs if certain individuals or observations in a population have a higher chance of being included in a sample than others. We say a sampling procedure is <strong>unbiased</strong> if every observation in a population had an equal chance of being sampled. Had the red beads been much smaller than the white beads, and therefore more prone to falling out of the shovel, our sample would have been <strong>biased</strong>. In our sampling activities, since we mixed all <span class="math inline">\(N = 1000\)</span> beads prior to each group’s sampling and since each of the equally sized beads had an equal chance of being sampled, our samples were unbiased.</p>
<p>Ninth, a sampling procedure is <em>random</em> if we sample randomly from the population in an unbiased fashion. In our sampling activities, this would correspond to sufficiently mixing the urn before each use of the shovel.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-497"></span>
<img src="06-one-parameter/images/cant_breathe_sponge.png" alt="Fear not if you look like Spongebob after reading this section. We will re-cap right now!" width="100%"><p class="caption">
FIGURE 6.16: Fear not if you look like Spongebob after reading this section. We will re-cap right now!
</p>
</div>
<p><strong>In general:</strong></p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>“good guess”</strong> of the unknown population parameter, thus</li>
<li>instead of performing a <strong>census</strong>, we can draw inferences about the population using <strong>sampling</strong>.</li>
</ul>
<p><strong>Specific to our sampling activity:</strong></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n=50\)</span> beads at <strong>random</strong>, in other words, we mix all of the equally sized beads before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn’s 1000 beads, thus</li>
<li>any result based on the shovel’s beads can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\hat{\rho}\)</span> of the <span class="math inline">\(n=50\)</span> beads in the shovel that are red is a <strong>“good guess”</strong> of the population proportion <span class="math inline">\(\rho\)</span> of the <span class="math inline">\(N=1000\)</span> beads that are red, thus</li>
<li>instead of manually going over all 1,000 beads in the urn, we can make <strong>inferences</strong> about the urn by using the results from the shovel.</li>
</ul>
</div>
<div id="sampling-definitions" class="section level3" number="6.3.2">
<h3>
<span class="header-section-number">6.3.2</span> Statistical definitions<a class="anchor" aria-label="anchor" href="#sampling-definitions"><i class="fas fa-link"></i></a>
</h3>
<p>Now, for some important statistical definitions related to sampling. As a refresher of our 1,000 repeated/replicated virtual samples of size <span class="math inline">\(n\)</span> = 25, <span class="math inline">\(n\)</span> = 50, and <span class="math inline">\(n\)</span> = 100 in Section <a href="one-parameter.html#virtual-sampling">6.2</a>, let’s display our figure showing the difference in proportions red according to different shovel sizes.</p>
<div class="figure">
<span id="fig:unnamed-chunk-498"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-498-1.png" alt="Previously seen three distributions of the sample proportion $\hat{
ho}$." width="100%"><p class="caption">
FIGURE 6.17: Previously seen three distributions of the sample proportion <span class="math inline">\(\hat{ ho}\)</span>.
</p>
</div>
<p>These types of distributions have a special name: <strong>sampling distributions</strong>; their visualization displays the effect of sampling variation on the distribution of a point estimate; in this case, the sample proportion <span class="math inline">\(\hat{\rho}\)</span>. Using these sampling distributions, for a given sample size <span class="math inline">\(n\)</span>, we can make statements about what values we typically expect.</p>
<p>For example, observe the centers of all three sampling distributions: they are all roughly centered around <span class="math inline">\(0.4 = 40\%\)</span>. Furthermore, observe that while we are somewhat likely to observe sample proportions of red beads of <span class="math inline">\(0.2 = 20\%\)</span> when using the shovel with 25 slots, we will almost never observe a proportion of 20% when using the shovel with 100 slots. Observe also the effect of sample size on the sampling variation. As the sample size <span class="math inline">\(n\)</span> increases from 25 to 50 to 100, the variation of the sampling distribution decreases and thus the values cluster more and more tightly around the same center of around 40%. We quantified this variation using the standard deviation of our sample proportions, seeing that the standard deviation decreases with the square root of the sample size:</p>
<div class="figure">
<span id="fig:unnamed-chunk-499"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-499-1.png" alt="Previously seen comparing standard deviations of proportions red for 100 different shovels" width="100%"><p class="caption">
FIGURE 6.18: Previously seen comparing standard deviations of proportions red for 100 different shovels
</p>
</div>
<p>So as the sample size increases, the standard deviation of the proportion of red beads decreases. This type of standard deviation has another special name: <strong>standard error</strong></p>
</div>
<div id="what-is-a-standard-error" class="section level3" number="6.3.3">
<h3>
<span class="header-section-number">6.3.3</span> What is a “standard error?”<a class="anchor" aria-label="anchor" href="#what-is-a-standard-error"><i class="fas fa-link"></i></a>
</h3>
<p>The “standard error” (SE) is a term that measures the accuracy with which a sample distribution represents a population through the use of standard deviation. Specifically, SE is used to refer to the standard deviation of a sample statistic (aka point estimate), such as the mean or median. For example, the “standard error of the mean” refers to the standard deviation of the distribution of sample means taken from a population.</p>
<blockquote>
<p>In statistics, a sample mean deviates from the actual mean of a population; this deviation is the standard error of the mean.</p>
</blockquote>
<p>Many students struggle to differentiate the standard error from the standard deviation. The relationship between the standard error and the standard deviation is such that, for a given sample size, the standard error equals the standard deviation divided by the square root of the sample size. Accordingly, the standard error is inversely proportional to the sample size; the larger the sample size, the smaller the standard error because the statistic will approach the actual value.</p>
<!-- Insert visual aid for students who are not mathematically inclined showing that larger sample sizes = closer to actual value -->
<p>The more data points involved in the calculations of the mean, the smaller the standard error tends to be. When the standard error is small, the data is said to be more representative of the true mean. In cases where the standard error is large, the data may have some notable irregularities. Thus, larger sample size = smaller standard error = more representative of the truth.</p>
<p>To help reinforce these concepts, let’s re-display our previous figure but using our new sampling terminology, notation, and definitions:</p>
<div class="figure">
<span id="fig:unnamed-chunk-500"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-500-1.png" alt="Three sampling distributions of the sample proportion $\hat{
ho}$. Note the increased concentration on the bins around .4 as our sample size increases." width="100%"><p class="caption">
FIGURE 6.19: Three sampling distributions of the sample proportion <span class="math inline">\(\hat{ ho}\)</span>. Note the increased concentration on the bins around .4 as our sample size increases.
</p>
</div>
<p>Furthermore, let’s display the graph of standard errors for <span class="math inline">\(n = 1\)</span> to <span class="math inline">\(n = 100\)</span> using our new terminology, notation, and definitions relating to sampling.</p>
<div class="figure">
<span id="fig:unnamed-chunk-501"></span>
<img src="book_temp_files/figure-html/unnamed-chunk-501-1.png" alt="Standard errors of the sample proportion based on sample sizes of 1 to 100" width="100%"><p class="caption">
FIGURE 6.20: Standard errors of the sample proportion based on sample sizes of 1 to 100
</p>
</div>
<p>Remember the key message of this last table: that as the sample size <span class="math inline">\(n\)</span> goes up, the “typical” error of your point estimate will go down, as quantified by the <em>standard error</em>.</p>
</div>
<div id="moral-of-the-story" class="section level3" number="6.3.4">
<h3>
<span class="header-section-number">6.3.4</span> The moral of the story<a class="anchor" aria-label="anchor" href="#moral-of-the-story"><i class="fas fa-link"></i></a>
</h3>
<p>If we could only know two pieces of information from our data, what would they be? First, you need a measure of the <strong>center</strong> of the distribution. This would include the mean or median, which shows the center of our data points. Second, we need a measure of the <strong>variability</strong> of the distribution. To understand our center, we must understand how different (or how spread) our data points are from one another. Thus, we need a measure like sd() or MAD. These are summary statistics which are necessary to understanding a distribution. Do those two figures encompass all you need to know about a distribution? No! But, if you are only allowed two numbers to keep, those are the most valuable.</p>
<blockquote>
<p>The mean or median is a good estimate for the center of the posterior and the standard error or mad is a good estimate for the variability of the posterior, with +/- 2 standard errors covering 95% of the outcomes.</p>
</blockquote>
<p>The standard error measures the accuracy of a sample distribution as compared to the population by using the standard deviation. Specifically, the standard deviation of our data points divided by the square root of the sample size. As such, we find that larger sample sizes = lower standard errors = more accurate and representative guesses.</p>
<p>To really drive home our point: standard error is just a fancy term for your uncertainty about something you don’t know. Standard error == our (uncertain) beliefs.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-502"></span>
<img src="06-one-parameter/images/final_preceptor.png" alt="If you are wondering how much you need to know, follow this helpful guide of the information we have learned this chapter!" width="100%"><p class="caption">
FIGURE 6.21: If you are wondering how much you need to know, follow this helpful guide of the information we have learned this chapter!
</p>
</div>
<!-- RS: Pyramid is not super helpful and I support removing it and all references to it.  -->
<p>This hierarchy represents the knowledge we need to understand standard error (SE). At the bottom, we have math. It’s the foundation for our understanding, but it doesn’t need to be what we take away from this lesson. As we go up, we simplify the topic. The top of the pyramid are the basic levels of understanding that will help you to remember in the future.</p>
<p>If I know your estimate plus or minus <em>two</em> standard errors, I know your 95% confidence interval. This is valuable information. Standard error is really just a measure for how uncertain we are about something we do not know, the thing we are estimating. When we recall SE, we should remember that, all in all, it’s a complicated concept that can be distilled into: the way old people talk about confidence intervals.</p>
<!-- RS: Explain what confidence interval is.  -->
<p>Recall that <span class="math inline">\(\hat{\rho}\)</span> is the estimated value of p which comes from taking a sample. There can be billions and billions of <span class="math inline">\(\hat{\rho}\)</span>’s. We look at a large group of <span class="math inline">\(\hat{\rho}\)</span>’s, create a distribution of results to represent the possible values of p based on our findings, and then we compute a standard error to account for our own uncertainty about our predictions. Our 95% confidence interval for our prediction == our estimate plus or minus <strong>two</strong> standard errors.</p>
<p>In regards to the fifth layer of the hierarchy, we may wonder:</p>
<blockquote>
<p>“I thought that MADs were the same thing as standard deviations. Now you say they are the same things as standard errors. Which is it?”</p>
</blockquote>
<p>MADs and standard deviations are, more or less, the same thing. They are both measures of the <strong>variability</strong> of a distribution. In most cases, they have very similar values. A <em>standard error</em> is also a standard deviation. Specifically, it is the standard deviation of the distribution of the estimates, and that distribution of estimates is, more or less, your posterior. Therefore, we can use MAD, like standard error, to describe that distribution and the variability of that distribution.</p>
</div>
</div>
<div id="urn-paradigm" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Urn paradigm<a class="anchor" aria-label="anchor" href="#urn-paradigm"><i class="fas fa-link"></i></a>
</h2>
<!-- Re-organize this around the Cardinal Virtues, just like Chapter 7. -->
<p>Recall the questions we asked at the beginning of our chapter:</p>
<p><em>If we get 17 red beads in a random sample of size 50 taken from a mixed urn, what proportion <span class="math inline">\(\rho\)</span> of the beads in the urn are red?</em></p>
<p><em>What is the probability, using the same urn, that we will draw more than 8 red beads if we use a shovel of size 20?</em></p>
<p>The urn paradigm provides us a simple problem for which we can learn new data science techniques before we tackle more complicated problems in later chapters. For any question, we use the Cardinal Virtues to guide our thinking. While this may seem trivial at first, as our problems become more complex it will become useful to have a systematic approach to break each problem into its parts. Let’s get to it.</p>
<div id="wisdom-1" class="section level3" number="6.4.1">
<h3>
<span class="header-section-number">6.4.1</span> Wisdom<a class="anchor" aria-label="anchor" href="#wisdom-1"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="other/images/Wisdom.jpg" width="100%"></div>
<p>This essence of Wisdom is determining whether or not a problem is even solvable. First, let’s break down our question into its key parts. Then we can construct a Preceptor Table to determine whether or not our data is viable to answer our question.</p>
<!-- Change "centered at" to reference p. Use rho instead of p -->
<!-- RS: Is there a specific paragraph you're referencing about changing "centered at" to reference p?   -->
<!-- RS: Change all p's to rho? -->
<div id="getting-started-1" class="section level4" number="6.4.1.1">
<h4>
<span class="header-section-number">6.4.1.1</span> Getting started<a class="anchor" aria-label="anchor" href="#getting-started-1"><i class="fas fa-link"></i></a>
</h4>
<p>Virtually every problem boils down to attempting to answer a <strong>question</strong> about a <strong>population</strong> using <strong>data</strong> and <strong>prior knowledge</strong>. We should explicitly state all 4 before we proceed, to make sure we understand the task at hand.</p>
<p>Let’s revisit our first question: <em>If we get 17 red beads in a random sample of size 50 taken from a mixed urn, what proportion <span class="math inline">\(\rho\)</span> of the beads in the urn are red?</em> We have a <em>question</em>: what proportion of the beads in the urn are red? Our question is asking us to solve for one population parameter, <span class="math inline">\(\rho\)</span>. The subject of the question is the <em>population</em>; in this case, the population is all the beads in <em>a mixed urn</em>. “A mixed urn” is very ambiguous, and we do not even know its size, but that is what the question provides us. There is an urn out there, somewhere, for which we want to know the proportion of red beads.</p>
<p>To answer our question, we have some <em>data</em>: in a random sample of size 50, <span class="math inline">\(17/50 = 34\%\)</span> of beads are red. The data we have is not to be confused with the <em>prior</em>, which is information that we know about our scenario <strong>before</strong> we collect our data that can come from our own general knowledge or other research. Let’s consider an example to differentiate the prior and data. If we flip a balanced coin, we know that there is a 50% chance of it landing on heads. This is the prior! If we then construct an experiment and flip a coin 10 times and record 4 heads, this is data that we can use as evidence for our prior.</p>
<p>The prior is often denoted as <span class="math inline">\(p(\theta)\)</span>, the probability distribution of a parameter <span class="math inline">\(\theta\)</span>. Essentially, the prior tells us that some values are more likely than others. In our urn scenario, we don’t have a prior, as we know nothing about our ambiguous intangible urn. Without prior knowledge, the proportion of red beads in the urn is equally likely to be any continuous value between 0 and 1, until we obtain data, and realize that the proportion of red beads is far more likely to be closer to .34 than an extreme value like .02 or .64. The prior is our initial beliefs, and the data we obtain updates those beliefs.</p>
<p>Now let’s break down our second question in a similar fashion to the first. Our <em>question</em> is: <em>what is the probability, using the same urn, that we will draw more than 8 red beads if we use a shovel of size 20?</em>. The question specifies using the “same urn,” so the <em>population</em> for both questions is the same. However, what is the <em>data</em> and <em>prior</em> for the second question? The reality is that we need to know the probability of selecting a red bead from the urn before we can determine the probability of selecting more than 8 red beads, and thus our second question is contingent on extracting a posterior probability distribution from the first question. As such, if we successfully pass through Wisdom and Justice, we can use the models we create in Courage to answer this question in Temperance. While that may be a mouthful at the moment, you will receive plenty of practice with the Cardinal Virtues throughout this <em>Primer</em>.</p>
<p>After successfully breaking down the problem, our next step is to construct a Preceptor Table.</p>
</div>
<div id="preceptor-tables-1" class="section level4" number="6.4.1.2">
<h4>
<span class="header-section-number">6.4.1.2</span> Preceptor Tables<a class="anchor" aria-label="anchor" href="#preceptor-tables-1"><i class="fas fa-link"></i></a>
</h4>
<p>Recall that a Preceptor Table is a table with rows and columns for all the data we would (reasonably) like to have. There are two different types of Preceptor Tables that are applicable to our urn example: actual and ideal.</p>
<div class="figure">
<span id="fig:unnamed-chunk-504"></span>
<img src="06-one-parameter/images/here_we_go.png" alt="When you see another Precetor Table section." width="100%"><p class="caption">
FIGURE 6.22: When you see another Precetor Table section.
</p>
</div>
<p>An actual Preceptor Table shows what we <em>actually</em> know. Accordingly, the table is riddled with question marks that the real world saddles us with. The ideal Preceptor Table is the Preceptor Table with no question marks, and a reasonable number of rows and columns. With an ideal Preceptor Table, there is no need for inference; the estimand is a simple matter of arithmetic.</p>
<p>To see if our data can answer our question, we first construct the ideal Preceptor Table, which simply requires knowing the color of every bead in our population. Unlike the Rubin Casual Preceptor Tables in Section <a href="rubin-causal-model.html#rubin-causal-model">4</a>, our actual preceptor table only requires one column. We can create the ideal Preceptor Table by performing the exhaustive census of the entire urn:</p>
<div id="dcnvtzwfly" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#dcnvtzwfly .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dcnvtzwfly .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dcnvtzwfly .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dcnvtzwfly .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dcnvtzwfly .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dcnvtzwfly .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dcnvtzwfly .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dcnvtzwfly .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dcnvtzwfly .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dcnvtzwfly .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dcnvtzwfly .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dcnvtzwfly .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#dcnvtzwfly .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dcnvtzwfly .gt_from_md > :first-child {
  margin-top: 0;
}

#dcnvtzwfly .gt_from_md > :last-child {
  margin-bottom: 0;
}

#dcnvtzwfly .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dcnvtzwfly .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#dcnvtzwfly .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dcnvtzwfly .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#dcnvtzwfly .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dcnvtzwfly .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dcnvtzwfly .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dcnvtzwfly .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dcnvtzwfly .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dcnvtzwfly .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#dcnvtzwfly .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dcnvtzwfly .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#dcnvtzwfly .gt_left {
  text-align: left;
}

#dcnvtzwfly .gt_center {
  text-align: center;
}

#dcnvtzwfly .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dcnvtzwfly .gt_font_normal {
  font-weight: normal;
}

#dcnvtzwfly .gt_font_bold {
  font-weight: bold;
}

#dcnvtzwfly .gt_font_italic {
  font-style: italic;
}

#dcnvtzwfly .gt_super {
  font-size: 65%;
}

#dcnvtzwfly .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">ID</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Color</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">1</td>
<td class="gt_row gt_center">white</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">2</td>
<td class="gt_row gt_center">white</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">200</td>
<td class="gt_row gt_center">red</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">201</td>
<td class="gt_row gt_center">white</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">1000</td>
<td class="gt_row gt_center">red</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
</tbody>
</table></div>
</div>
<p> </p>
<p>With an ideal Preceptor Table, the estimand, the proportion of red beads in the urn, is a simple matter of arithmetic: count the number of red beads and divide by the total number of beads in the urn. Note, however, that counting each bead in the urn would be impossible, as we have no access to the urn. This is denoted by the three dots at the bottom of our Preceptor Table, as our problem never specified whether our urn has a thousand, a million, or even a billion beads. Instead, we use our sample of data.</p>
<p>But can our data even answer our question? Above we determined that we need one column, bead color, in order to answer our question. If we use our sample, we have color identifications for 50 beads in the urn, so our data can technically be used. While determining if our data can be used is very basic in our urn scenario, let’s turn to an alternate example: if we had a sample of housing prices in a neighborhood, can we use that data to draw conclusions about the income of individuals in the neighborhood? In this scenario we must consider if our housing data is enough to fill in our ideal preceptor table, and if we believe the data cannot accurately solve our problem, we need to stop and find new data!</p>
<p>We now turn to our sampled data to create an actual Preceptor Table. Our data tells us that 17 out of the 50, or 34% of the <em>sampled</em> beads are red. Let’s visualize this by looking at the entire urn after we have taken our sample. This is an actual Preceptor Table. We only know the colors of our randomly sampled 50 beads, the remaining bead colors are our missing data!</p>
<div id="meesrzyepf" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#meesrzyepf .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#meesrzyepf .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#meesrzyepf .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#meesrzyepf .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#meesrzyepf .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#meesrzyepf .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#meesrzyepf .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#meesrzyepf .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#meesrzyepf .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#meesrzyepf .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#meesrzyepf .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#meesrzyepf .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#meesrzyepf .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#meesrzyepf .gt_from_md > :first-child {
  margin-top: 0;
}

#meesrzyepf .gt_from_md > :last-child {
  margin-bottom: 0;
}

#meesrzyepf .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#meesrzyepf .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#meesrzyepf .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#meesrzyepf .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#meesrzyepf .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#meesrzyepf .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#meesrzyepf .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#meesrzyepf .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#meesrzyepf .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#meesrzyepf .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#meesrzyepf .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#meesrzyepf .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#meesrzyepf .gt_left {
  text-align: left;
}

#meesrzyepf .gt_center {
  text-align: center;
}

#meesrzyepf .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#meesrzyepf .gt_font_normal {
  font-weight: normal;
}

#meesrzyepf .gt_font_bold {
  font-weight: bold;
}

#meesrzyepf .gt_font_italic {
  font-style: italic;
}

#meesrzyepf .gt_super {
  font-size: 65%;
}

#meesrzyepf .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">ID</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Color</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">1</td>
<td class="gt_row gt_center">?</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">2</td>
<td class="gt_row gt_center">white</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">200</td>
<td class="gt_row gt_center">red</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">201</td>
<td class="gt_row gt_center">?</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">...</td>
<td class="gt_row gt_center">...</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">999</td>
<td class="gt_row gt_center">white</td>
</tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000;">1000</td>
<td class="gt_row gt_center">?</td>
</tr>
</tbody>
</table></div>
</div>
<p> </p>
<p>Where is all of our data? Well, when we take a sample of 50 beads, we only have color identifications for 50 of the unknown number of beads in the urn. The rest of the beads were not sampled and we cannot say for certain whether they are white or red.</p>
<p>Now, what does our actual Preceptor Table tell us, specifically, about Bead 1? Bead 2? We know the proportion of red beads in our sample is 34%. Does this mean that bead 1 has <em>precisely</em> a 34% chance of being red? As we learned in Chapter 5, this is not true! There is uncertainty.</p>
<p>We can only claim <em>for certain</em> that, of the 50 beads that we sampled, 34% were red. If we were making a prediction of the probability of one of our <strong>sampled</strong> beads being red, 34% would be the correct probability. If we were making a prediction of the probability that an <strong>unsampled</strong> bead was red, the answer of 34% would be incorrect, but nor is it likely to be extremely incorrect. The sample does tell us something.</p>
<p>The last step of Wisdom to consider is why some beads <strong>do</strong> get sampled, while others do not. This is a consequence of the sampling mechanism. We need to take any biases into consideration, so we can evaluate the validity and representatives of our data in Justice. Keep in mind that just because our data can answer our question <strong>never</strong> means that we should use it! For example, what if our beads were mixed poorly, and most of the red beads sit at the bottom of the urn. In that case, our sampling mechanism consisting of the shovel with 50 slots after mixing the urn, would produce biased samples that would not be conclusive about the contents of the entire urn. The effects of biases can be determined later in Justice, but we need to know they exist in Wisdom.</p>
</div>
</div>
<div id="justice-1" class="section level3" number="6.4.2">
<h3>
<span class="header-section-number">6.4.2</span> Justice<a class="anchor" aria-label="anchor" href="#justice-1"><i class="fas fa-link"></i></a>
</h3>
<!-- RS: This chapter is already going to be pretty long so I think discussion of Population Table is not worth the space, plus Ch. 7 does a pretty good job already.  -->
<div class="inline-figure"><img src="other/images/Justice.jpg" width="100%"></div>
<div id="representativeness-and-validity" class="section level4" number="6.4.2.1">
<h4>
<span class="header-section-number">6.4.2.1</span> Representativeness and validity<a class="anchor" aria-label="anchor" href="#representativeness-and-validity"><i class="fas fa-link"></i></a>
</h4>
<p>Now that we’ve determined that our data <em>could</em> be used, Justice asks if it <em>should</em> be used by analyzing the sampling mechanism. If we want to draw conclusions about an entire population using a small subset of its individuals, then we want to consider the representativeness and the validity of our data. Skipping Justice puts us at risk of creating models with “bad data,” which would lead us to incorrect or misleading conclusions.</p>
<p><strong>Representativeness</strong> involves our rows. More specifically, are the rows that we do have data for representative of the rows for which we do not have data? In our urn, our data is representative of the population if the proportion of red beads in our sample is close enough to the actual proportion of red beads in the whole urn. For the sample proportion to be similar to the actual population proportion, we ideally want the data we have to be a random, unbiased selection from our population, using a considerable sample size. This rarely occurs in real life! But in the context of our problem, the sampling mechanism of using a shovel of size 50 to sample beads from a <strong>mixed</strong> urn should be enough to consider our sample representative of the population, and we can move on.</p>
<p><strong>Validity</strong> involves the columns of our data set. Is the meaning of our columns consistent across our dataset(s) and ideal Preceptor Table? In our urn scenario, does bead color in our sampled data and bead color in our Preceptor Table mean the same thing? The answer is yes, and validity can be assumed very easily. In Section <a href="two-parameters.html#two-parameters">7</a> analyzing representativeness and validity will become considerably more challenging.</p>
</div>
<div id="the-dgm" class="section level4" number="6.4.2.2">
<h4>
<span class="header-section-number">6.4.2.2</span> The DGM<a class="anchor" aria-label="anchor" href="#the-dgm"><i class="fas fa-link"></i></a>
</h4>
<p>The final aspect of Justice is producing a mathematical formula that can model our situation. Our models are only as good as the equations we use to make them, so choose with care.</p>
<p>One of the most important terms in statistics and data science is the <strong>Data Generating Mechanism</strong>, or DGM. The DGM is simply how each individual outcome, <span class="math inline">\(y_i\)</span>, comes into existence. In general, the DGM is often denoted as follows:</p>
<p><span class="math display">\[ y_i  \sim p(y_i | \theta) \]</span></p>
<p>Don’t get caught up by the equation. It just means that our outcome is chosen based on some given parameter, <span class="math inline">\(\theta\)</span>. If we change the value of the parameter, our outcome is likely to change as well.</p>
<p>We can create a DGM for our specific urn scenario. In this <em>Primer</em>, we most frequently use either normal (Gausian) distributions or binomial distributions. In our urn we count the number of red beads selected, and do not count the white beads. This success/failure or TRUE/FALSE relationship strongly suggests we should use a binomial distribution to model our situation. We can rework the DGM equation to suit our needs:</p>
<p><span class="math display">\[ T_i  \sim B(\rho_r, n = 50) \]</span></p>
<p>The total number of red beads selected in ONE specific experiment with 50 sampled beads, <span class="math inline">\(T_i\)</span>, occurs from taking one draw from a binomial distribution with <span class="math inline">\(n = 50\)</span> observations and an unknown probability <span class="math inline">\(\rho_r\)</span> of the proportion of red beads in the urn.</p>
</div>
</div>
<div id="courage-1" class="section level3" number="6.4.3">
<h3>
<span class="header-section-number">6.4.3</span> Courage<a class="anchor" aria-label="anchor" href="#courage-1"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="other/images/Courage.jpg" width="100%"></div>
<p>We’ve evaluated our data and questions and chosen a mathematical formula. Now it’s time to work on our code to create a model that can simulate the real world.</p>
<div id="bayesian-framework" class="section level4" number="6.4.3.1">
<h4>
<span class="header-section-number">6.4.3.1</span> Bayesian framework<a class="anchor" aria-label="anchor" href="#bayesian-framework"><i class="fas fa-link"></i></a>
</h4>
<p>We are Bayesian data scientists that make Bayesian models. This means that we make specific assumptions and consider different things to be either fixed or variable compared to other data science frameworks. One of the most important distinctions is that in Bayesian data science, <strong>we don’t know the values of our parameters</strong>. Consider the DGM created in Justice:</p>
<p><span class="math display">\[ T_i  \sim B(\rho_r, n = 50) \]</span></p>
<p>Some non-Bayesian frameworks are concerned with the probability distribution of our observed data, but do not care much about the probability distribution for <span class="math inline">\(\rho_r\)</span> and assume it to be fixed. If <span class="math inline">\(\rho_r\)</span> is fixed, the equation above becomes one simple binomial distribution. Think of this as a standard 2 dimensional plot.</p>
<p>Us Bayesians consider our observed data to be fixed. We don’t consider alternate realities where our observed data is different due to sampling variation. Instead, we are concerned with the probability distribution of our parameter. In our urn scenario, <span class="math inline">\(\rho_r\)</span> is variable, so we have to create a separate binomial distribution for each possible value of <span class="math inline">\(\rho_r\)</span>. Think of this as a 3 dimensional joint distribution like what we created in Section <a href="probability.html#n-models">5.6</a>.</p>
<p>One of the foundations of Bayesian data science is Bayes’ theorem, created by Thomas Bayes:</p>
<p><span class="math display">\[  p(\theta | y) = \frac{p(y|\theta)p(\theta)}{p(y)} \]</span></p>
<p>We do not care enough to try and understand how this equations works! The equation itself is not helpful to us, but understanding the different terms within it will help our modeling endeavors.</p>
<ul>
<li>
<strong>The joint distribution</strong>, <span class="math inline">\(p(y|\theta)\)</span>, represents the exact same concept we addressed while discussing the distinctions of Bayesian science: because our parameters are variable, we have to create distributions for each potential value. Combining all these distributions together creates a joint distribution that is 3 dimensional when plotted.</li>
</ul>
<p>Careful readers may note that the equation for the joint distribution, <span class="math inline">\(p(y|\theta)\)</span>, appears to be very similar to the equation for the DGM, <span class="math inline">\(p(y_i|\theta)\)</span>. They are indeed similar, but know that the joint distribution models all outcomes, while the DGM models selecting one individual outcome, <span class="math inline">\(y_i\)</span>. Also know that many data scientists refer to the joint distribution as “the likelihood.”</p>
<ul>
<li>
<strong>The prior</strong>, <span class="math inline">\(p(\theta)\)</span>, is the probability distribution that describes our uncertainty surrounding our parameter(s) <span class="math inline">\(\theta\)</span>. We create the prior from any information we have <strong>before</strong> we collect data. The more descriptive the information we have, the more descriptive the prior, and the less error we have in our model as we know that some values are far more likely to occur than others.</li>
</ul>
<p>In Wisdom, we stated that we do not have any prior information. Some of us might argue that we do have a prior, as we know 17 out of 50, or 34% of our sampled beads our red. Our sample is in fact data, and should not be confused with the prior. Because we have no prior information, the proportion of red beads in the urn could be any value between 0 and 1. It appears we know nothing until the data updates our beliefs to create a posterior distribution.</p>
<ul>
<li>
<strong>The posterior</strong>, <span class="math inline">\(p(\theta|y)\)</span>, is the result of Bayes’ theorem and is our coveted end goal. The posterior is the probability distribution of our parameters, created using data that updates our prior beliefs. We have referenced the posterior many times before, and this definition does not change its meaning.</li>
</ul>
<p>In our urn scenario, obtaining the posterior involves first creating many binomial distributions for each possible population proportion. This is the joint distribution, and it is a 3 dimensional model. We then select the distribution that corresponds with our data: 17 red beads are sampled. We can represent the posterior with the following:</p>
<p><span class="math display">\[\text{Prob}(\text{models} | \text{data} = 17)\]</span></p>
<p>This is equivalent to taking a 2 dimensional slice of the 3 dimensional model. We are left with a probability distribution for our parameter, <span class="math inline">\(\rho\)</span>.</p>
</div>
<div id="stan_glm" class="section level4" number="6.4.3.2">
<h4>
<span class="header-section-number">6.4.3.2</span> stan_glm()<a class="anchor" aria-label="anchor" href="#stan_glm"><i class="fas fa-link"></i></a>
</h4>
<p>In Chapter <a href="probability.html#probability">5</a>, we first started our tibble with a range of possible values for our parameter <span class="math inline">\(\rho\)</span>. We then took samples using each possible value to create the 3 dimensional joint distribution. Finally, we took a slice of the joint distribution based on the data we collected, to create the posterior probability distribution. This is not how professionals work. Many data scientists use the <strong>rstanarm</strong> package, which provides a user friendly interface to work with the statistical language Stan.</p>
<p><strong>rstanarm</strong> and Stan are appealing because they are powerful. Functions such as <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> can do everything we did by hand in Chapter 5 in a few lines of code. Because we will use a professional statistical library, the objects we make will become more complex. In this chapter we will explain our models in terms of high level Bayesian concepts, and Chapter <a href="two-parameters.html#two-parameters">7</a> will provide a more detailed explanation of the objects we will make. <strong>To be clear, you do not need to fully understand this section or how this code works. This is an introduction, not a formal lesson.</strong></p>
<p>Again, we are attempting to answer this question: <em>If we get 17 red beads in a random sample of size 50 taken from a mixed urn, what proportion <span class="math inline">\(\rho\)</span> of the beads in the urn are red?</em></p>
<p>We want to estimate the value of <span class="math inline">\(\rho\)</span>, but because us Bayesians consider <span class="math inline">\(\rho\)</span> to be variable, we need to create a posterior distribution that addresses our uncertainty regarding its true value. We can easily create the posterior by using <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code>. Let’s go ahead and create our model, and then view the results in a tibble.</p>
<div class="sourceCode" id="cb682"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span>

<span class="va">fit_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">red</span> <span class="op">~</span> <span class="fl">1</span>, 
                  data <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>red <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">17</span><span class="op">)</span>, 
                                        <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">33</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
                  family <span class="op">=</span> <span class="va">binomial</span>,
                  refresh <span class="op">=</span> <span class="fl">0</span>,
                  seed <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> 

<span class="va">fit_1</span> <span class="op">%&gt;%</span>
  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 4,000 x 1
##    `(Intercept)`
##            &lt;dbl&gt;
##  1        -1.54 
##  2        -1.62 
##  3        -1.56 
##  4        -1.12 
##  5        -1.06 
##  6        -1.06 
##  7        -1.14 
##  8        -1.14 
##  9        -0.815
## 10        -0.848
## # … with 3,990 more rows</code></pre>
<p>This tibble shows us 4,000 draws from the posterior distribution.<code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> simplifies all the work which we did by hand previously into one single function. We can also visualize our 4,000 draws from the posterior in a histogram:</p>
<div class="sourceCode" id="cb684"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_1</span> <span class="op">%&gt;%</span>
  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
   <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">`(Intercept)`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
                   bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"4,000 draws from the Posterior Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Why is the x axis negative? We will address this soon."</span>,
         x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">rho</span><span class="op">)</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu">scale_x_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_number.html">number_format</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_percent.html">percent_format</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-510-1.png" width="100%"></div>
<p>Let’s examine the purpose of the arguments used within <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> in terms of high level Bayesian concepts.</p>
<ul>
<li><p><strong>The prior</strong>: Recall that we do not have a prior for our urn, so we add nothing to our model. With problems that contain covariates like in Chapter <a href="two-parameters.html#two-parameters">7</a>, <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> will create weakly informative priors based on our predictor variables by auto-rescaling the posterior for us. <strong>The problems in this Primer do not require us to create our own priors, and as such we will not worry about them.</strong></p></li>
<li><p><strong>The joint distribution</strong>: The <code>family</code> and <code>formula</code> arguments relate to the joint distribution, also known as the likelihood by some. In Justice, we created the following model for our sampling mechanism:</p></li>
</ul>
<p><span class="math display">\[ T_i  \sim B(\rho_r, n = 50) \]</span></p>
<p>This is a binomial distribution. In <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> we denote this with <code>family = binomial</code>. In addition to the type of the distribution, we also need to analyze the outcome and predictor variables involved. The outcome is the quantity we are measuring, in this case the total number of red beads in our sample, <span class="math inline">\(T_i\)</span>. Covariates are continuous predictor variables that help forecast our outcome. For example, age is a covariate that effects the outcome of someone’s blood pressure. Because we only measure how many red beads are in the sample (the outcome), we have no covariates which we can use to make our model more accurate. Because we have no predictors, we use the argument <code>formula = red ~ 1</code>, which means that we only model the outcome without the consideration of any covariates.</p>
<ul>
<li><p><strong>The data</strong>: We are required to pass data into the <code>data</code> argument in order for <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> to “take a slice” of the joint distribution and estimate the posterior. Because we are measuring the total number of red beads in a sample, <span class="math inline">\(T_i\)</span>, we pass in data in a binomial format: the 1’s represent the number of successes (red beads drawn), and the 0’s represent the number of failures (white beads drawn). As such, we pass a tibble with 17 red beads and 33 white beads into <code>data</code>.</p></li>
<li><p>Other arguments: we use <code>refresh = 0</code> to suppress the behavior of printing to the console, and <code>seed = 10</code> to make produce the same output every time we run the code.</p></li>
</ul>
<p>Once we have the <code>fit_1</code> object, it is easy to answer two sorts of questions: the posterior probability distribution for <span class="math inline">\(\rho\)</span> and predictions for new draws from the urn. The key new functions are <code><a href="https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html">posterior_epred()</a></code> for the former and <code><a href="https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html">posterior_predict()</a></code> for the latter.</p>
</div>
<div id="answering-the-questions" class="section level4" number="6.4.3.3">
<h4>
<span class="header-section-number">6.4.3.3</span> Answering the questions<a class="anchor" aria-label="anchor" href="#answering-the-questions"><i class="fas fa-link"></i></a>
</h4>
<p>There are some questions left to be answered. Let’s attempt to answer them here.</p>
<blockquote>
<p>Why is the x axis of the posterior distribution negative? Shouldn’t all values be between 0 and 1?</p>
</blockquote>
<p>The x axis of our posterior is negative because for binomial models, <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> chooses to use the “logit” function to convert our probabilities. We can use <code><a href="https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html">posterior_epred()</a></code> to find the <em>ex</em>pected <em>prediction</em> of our posterior without the logit function. Know that we do not just use <code><a href="https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html">posterior_epred()</a></code> to undo transformations. We will use it many more times throughout this <em>Primer</em> to create the expected distribution based off some covariate. Let’s recreate our posterior using <code><a href="https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html">posterior_epred()</a></code>:</p>
<div class="sourceCode" id="cb685"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ppd_for_p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html">posterior_epred</a></span><span class="op">(</span><span class="va">fit_1</span>, 
                newdata <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>constant <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span>

<span class="va">ppd_for_p</span></code></pre></div>
<pre><code>## # A tibble: 4,000 x 1
##      `1`
##    &lt;dbl&gt;
##  1 0.176
##  2 0.165
##  3 0.173
##  4 0.246
##  5 0.258
##  6 0.258
##  7 0.243
##  8 0.242
##  9 0.307
## 10 0.300
## # … with 3,990 more rows</code></pre>
<p>Because we do not wish to create our distribution conditional on some covariate, we want to pass in a tibble with 1 row into the <code>newdata</code> argument. An empty tibble has 0 rows, so we instead pass in a tibble with some junk data. <code>constant = 1</code> is completely meaningless. We can verify that the posterior is the same by plotting it. Hopefully it should have a similar shape, but all values should be between 0 and 1.</p>
<div class="sourceCode" id="cb687"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ppd_for_p</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">`1`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
                   bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Distribution shape is the same as earlier, but the proportion red is centered at .34"</span>,
         x <span class="op">=</span> <span class="st">"Proportion p of Red Beads in Urn"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span> 
  
    <span class="fu">scale_x_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_number.html">number_format</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_percent.html">percent_format</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-512-1.png" width="100%"></div>
<p>Now that our posterior probability distribution is correctly centered, we have successfully created the posterior distribution and can finally answer the question we started the chapter with: <em>If we get 17 red beads in a random sample of size 50 taken from a mixed urn, what proportion <span class="math inline">\(\rho\)</span> of the beads in the urn are red?</em></p>
<p>Look to the distribution we have created! We can see that the bulk of the area under the posterior occurs approximately when <span class="math inline">\(\rho\)</span> is between .28 and .42, so the answer to our question is that it is likely that 28 to 42 percent of the beads in the urn in the red. Although the most likely probability (the highest bar on the histogram) occurs when <span class="math inline">\(\rho\)</span> is around .32, The answer is not a single number. Our posterior distribution is just that: a distribution. From our sample, we have many different results for the proportion of red beads in the entire urn. Certain proportions, like the extremes close to 0% or 100%, are essentially impossible due to our sample value being 34%. On the other hand, we could have just as easily sampled 16 or 18 beads from the urn, and sample proportions such as 32% and 36% are very plausible.</p>
<p>This means that, while we can provide a range of possibilities (and we can estimate which of those possibilities occur most frequently), we can never say that we know the total number of red beads with certainty. We know that there is the most chance that <span class="math inline">\(\rho\)</span> is between .28 and about .42, some chance that <span class="math inline">\(\rho\)</span> is between .15 and .24 or between .42 and .56, and almost no chance that <span class="math inline">\(\rho\)</span> is below .15 or above .56. With the posterior we can answer all these questions at once.</p>
<p>The key issue with the urn paradigm is that, unlike real world data science, we <em>can</em> technically find the true proportion. We just have to perform that exhaustive count that we’ve been so desperately avoiding. In the real world, the “true” solution can never be known. This is why we require inference, and why tools like sampling are so helpful for drawing conclusions about the world around us.</p>
<p>If we had decided to, we could have answered this question using pure statistics. First calculate the standard error given 34% of the beads in the sample are red out of a sample size of 50:</p>
<p><span class="math display">\[  SE = \sqrt\frac{.34(1-.34)}{50} \approx .067\]</span></p>
<p>We can then create a 95% confidence interval:</p>
<p><span class="math display">\[  CI = \bar{x} \hspace{.1cm} \pm 2SE = .34 \hspace{.1cm} \pm .134\]</span></p>
<p>With 95% confidence, the proportion of red beads in the urn is between 21% and 47%. This is correct, but quite difficult to conceptualize. As data scientists we create the posterior distribution to answer all our questions. A single confidence interval does very little good.</p>
<p>Here is a second question that some of us may want answered:</p>
<blockquote>
<p>Why are there 4,000 rows in the stan_glm() tibble?</p>
</blockquote>
<p>By default, <code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> will sample from the posterior in 2 sets of 2,000 iterations. If needed we can change the default number of iterations using the <code>iter</code> argument, but there are few reasons to do so. Some of us may still want to know why we sample from the posterior in the first place. The posterior is a theoretical beast, which makes it difficult to work with.</p>
<p>For example, what if we wanted to know the probability that <span class="math inline">\(\rho\)</span> is above .4? To answer this, we would simply divide the number of draws that are above .4 by the total number of draws. However, the posterior is a distribution, so it has no indivisual observations because it’s infinite! Instead, we can work with draws from the posterior. The more draws, the more our distribution looks like the posterior. We can easily answer our question:</p>
<div class="sourceCode" id="cb688"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">ppd_for_p</span><span class="op">$</span><span class="va">`1`</span> <span class="op">&gt;</span> <span class="fl">.4</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">ppd_for_p</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 0.19</code></pre>
<p>There is approximately a 20% chance that <span class="math inline">\(\rho\)</span> is above .4. Give me draws from the posterior and I can show you the world!</p>
<div class="figure">
<span id="fig:unnamed-chunk-514"></span>
<iframe src="https://www.youtube.com/embed/sVxUUotm1P4?showcase=0" width="100%" height="400px">
</iframe>
<p class="caption">
FIGURE 6.23: Let’s take a quick musical interlude. We’ve earned it.
</p>
</div>
</div>
</div>
<div id="temperance-1" class="section level3" number="6.4.4">
<h3>
<span class="header-section-number">6.4.4</span> Temperance<a class="anchor" aria-label="anchor" href="#temperance-1"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="other/images/Temperance.jpg" width="100%"></div>
<p>Now that we have our posterior distribution for the proportion <span class="math inline">\(\rho\)</span> of red beads in the urn, we can use that object to forecast other outcomes, outcomes which we have not yet observed. Recall, from the start of the Chapter:</p>
<p><em>What is the probability, using the same urn, that we will draw more than 8 red beads if we use a shovel of size 20?</em></p>
<div id="using-the-posterior" class="section level4" number="6.4.4.1">
<h4>
<span class="header-section-number">6.4.4.1</span> Using the posterior<a class="anchor" aria-label="anchor" href="#using-the-posterior"><i class="fas fa-link"></i></a>
</h4>
<p>Whenever someone asks you a question, you need to decide what posterior probability distribution would make it easy for you to answer that question. In this case, if we know the posterior probability distribution for the number of red beads in a shovel of size 20, then a question about the likelihood of drawing more than 8 (or any other value) is easy to answer.</p>
<p>The posterior probability distribution for a probability is a tricky thing. It is much easier just to estimate the posterior probability distribution for the outcome — number of red beads out of 20 — and then work with that distribution in order to answer probability-type questions.</p>
<div class="sourceCode" id="cb690"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ppd_reds_in_20</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">fit_1</span>, 
                    newdata <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>constant <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>total <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="fu">across</span><span class="op">(</span><span class="va">`1`</span><span class="op">:</span><span class="va">`20`</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">total</span><span class="op">)</span>

<span class="va">ppd_reds_in_20</span> </code></pre></div>
<pre><code>## # A tibble: 4,000 x 1
##    total
##    &lt;dbl&gt;
##  1     6
##  2     4
##  3     3
##  4     5
##  5     3
##  6     7
##  7     6
##  8     7
##  9     5
## 10     6
## # … with 3,990 more rows</code></pre>
<!-- Example: sum(ppd_reds_in_20 > 8)/4000 is how we use the ppd to answer the question. -->
<div class="sourceCode" id="cb692"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ppd_reds_in_20</span>  <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">total</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
                   bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of red beads in 20-place shovel"</span>,
         x <span class="op">=</span> <span class="st">"Number of Red Beads"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu">scale_x_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_number.html">number_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/label_percent.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-517-1.png" width="100%"></div>
<!-- DK: Need to add discussion about answering different questions with this object. See the old discussion below. These words are good stuff! -->
<!-- The answer is about r round(100 *sum(post_dist$new_reds > 8) /  length(post_dist$new_reds))%. To observe this visually, take a look at the `post_dist` object when we filter for where the number of red beads is equal to and greater than 8. The answer above measures the area under *this* portion of the curve as compared to the *entire* area under the curve. *Each question requires looking at a new area under the curve.* When someones asks you a question, they are doing two things. First, they are providing instructions as to the posterior your should create. Here, the results with a shovel of 20 slots. Second, they are asking a question about the area under the curve in a specific region. Here, the region where the number of red beads is greater than 8 is highlighted in red. Therefore, the area below the curve that **is red** is how we get our estimate. -->
<!-- post_dist %>%  -->
<!--   # Create a column above_eight to identify True or False for new_reds being -->
<!--   # above eight. -->
<!--   mutate(above_eight = ifelse(new_reds > 8, "True", "False")) %>%  -->
<!--   # Set fill as above_eight. -->
<!--   ggplot(aes(x = new_reds, fill = above_eight)) + -->
<!--     geom_histogram(aes(y = after_stat(count/sum(count))), -->
<!--                    bins = 50) + -->
<!--   # Scale_fill_manual() here is calling grey for the first color and red for the -->
<!--   # second color. This is going to highlight the portion of the curve that we -->
<!--   # need to isolate in red. -->
<!--   scale_fill_manual(values = c('grey50', 'red'))+ -->
<!--     labs(title = "Posterior Probability Distribution", -->
<!--          subtitle = "Number of red beads in new draw of 20", -->
<!--          x = "Number of Red Beads", -->
<!--          y = "Probability", -->
<!--          fill = "Above Eight Beads?") +  -->
<!--     scale_x_continuous(labels = scales::number_format(accuracy = 1)) + -->
<!--     scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + -->
<!--     theme_classic() -->
<p>See Chapter <a href="two-parameters.html#two-parameters">7</a> for a thorough discussion of the use of <strong>rstanarm</strong>. This package will be our main tool for the rest of the <em>Primer</em>.</p>
</div>
<div id="hypothesis-tests" class="section level4" number="6.4.4.2">
<h4>
<span class="header-section-number">6.4.4.2</span> Hypothesis tests<a class="anchor" aria-label="anchor" href="#hypothesis-tests"><i class="fas fa-link"></i></a>
</h4>
<!-- RS: Use confidence intervals in this section, additional reinforcement.  -->
<p>Recall our view on hypothesis tests: <strong>Amateurs test. Professionals summarize.</strong> Traditionally, most scientific papers are not so much interested in estimating p. They are interested in testing specific hypotheses. What do we mean by that?</p>
<p>Let’s look at a possible hypothesis in our urn paradigm: there are equal number of red and white beads in the urn. The null hypothesis is denoted by <span class="math inline">\(H_0\)</span>, while the alternative hypothesis is denoted by <span class="math inline">\(H_a\)</span>. Therefore, our hypothesis is designed as such:</p>
<p><span class="math inline">\(H_0\)</span>: There are an equal number of red and white beads in the urn.
<span class="math inline">\(H_a\)</span>: There are <em>not</em> an equal number of red and white beads in the urn.</p>
<p>Can we reject that hypothesis? Convention: if the 95% confidence interval excludes the null hypothesis, then we reject it. Here, that would mean if our posterior estimate (plus or minus 2 standard errors) <em>excluded</em> the possibility of the red and white beads being equal, translating into a proportion red of 50%, we can reject the null hypothesis. Otherwise, we don’t reject it. However, this does not mean that we accept it. More to the point: rejecting or not rejecting hypotheses doesn’t helps us to answer real questions. There is no reason to <strong>test</strong> when you can summarize by providing the full posterior probability distribution, as we will do below.</p>
<p>The same arguments apply in the case of “insignificant” results, with p &gt; 0.5, when we can’t “reject” the null hypothesis. The fact that a difference is not “significant” has no relevance to how we use the posterior to make decisions. The same reasoning applies to every parameter we estimate, to every prediction we make. Never test — unless your boss demands a test. <strong>Use your judgment, make your models, summarize your knowledge of the world, and use that summary to make decisions.</strong> In the next section, we will create our posterior distribution and use this posterior to predict outcomes.</p>
<p>To examine the validity of our final conclusion, let’s look to our Cardinal Virtues.</p>
</div>
</div>
<div id="cardinal-virtues-1" class="section level3" number="6.4.5">
<h3>
<span class="header-section-number">6.4.5</span> Cardinal virtues<a class="anchor" aria-label="anchor" href="#cardinal-virtues-1"><i class="fas fa-link"></i></a>
</h3>
<!-- RS: I like the cardinal virtues motif, and I think we could implement something cool wherever they appear throughout the primer. I don't have any ideas right now, but maybe someone can think of something cool.  -->
<p>Recall the virtue of Wisdom. We want to know if there is a decent connection between the problem we face and the data we have. Our problem is answering the following question: <em>Conditional on our answer to Question 1, what is the probability, using the same urn, that we will draw more than 8 red beads if we use a shovel of size 20?</em> The way in which we have approached answering this question is to, from our posterior distribution from our urn, create a joint distribution to estimate the probability of drawing more than 8 red beads with a shovel of size 20. Is this question about <em>this</em> particular urn, or all urns? Clearly, as it is conditional upon a result from our specific urn, our conclusions can only be applied to <em>this particular urn</em>; our conclusions are not generalizable to all urns.</p>
<p>Justice encompasses two main topics that apply to our urn: predictive versus causal model and mathematical formulas. Are we are modeling (just) for prediction or are we (also) modeling for causation? Predictive models care nothing about causation. With prediction, all we care about is forecasting Y given X on some as-yet-unseen data. There is no notion of “manipulation” in such models. As we can see, then, our model is <strong>predictive</strong>; we are not manipulating anything. The math of our model can be:
<span class="math display">\[ T_i  \sim B(p_H, n = 20) \]</span>
The total number <span class="math inline">\(T\)</span> of red beads in experiment <span class="math inline">\(i\)</span> with 20 sampled beads, <span class="math inline">\(T_i\)</span>, is distributed as a binomial with <span class="math inline">\(n = 20\)</span> and an unknown probability <span class="math inline">\(\rho_h\)</span> of the proportion red exceeding 8 out of 20 beads.</p>
<p>Courage focuses on code – the structure of our model. Code allows us to “fit” a model by estimating the values of the unknown parameters. Though we can never know the true values of these parameters, we can express our uncertain knowledge in the form of posterior probability distributions. With those distributions, we can compare the actual values of the outcome variable with the “fitted” or “predicted” results of the model. We can examine the “residuals,” the difference between the fitted and actual values. To answer our question, we have taken a slice of our posterior distribution to create a joint distribution. To find our final solution, we looked at the area under the curve that includes all values of 8 red beads or above.</p>
<!-- RS: Kind of confused about the vocab. Didn't we go from joint to posterior probability to another posterior probability? Also I mentioned this earlier but shouldn't we create another joint distribution with p and phat? -->
<p>When we think of Temperance, we should think of uncertainty. Asserting a posterior distribution is, conceptually, the same as opening a casino and allowing people to place wagers on outcomes, with the odds consistent with your posterior. If your posterior is wrong, they will take all your money. That would be bad! So, what do we do? Rule of thumb: the future is always more variable than our models would suggest. The entire point of the virtue of Temperance to be aware of that fact and take account of it. Courage — that bold bastard — comes along and says, “Here is the model! Let’s calculate the posterior and open the casino!” Temperance says, “Hold on! Yes, I can calculate the posterior, but we need to be cautious.” Temperance is concerned with the tails of our predictions, not the center. What is the best strategy for opening our casino, then? Limit the bets on the first few nights to make sure our posterior is OK. <em>Temperance is concerned with the sensible management of the casino.</em></p>
</div>
</div>
<div id="discussion" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Discussion<a class="anchor" aria-label="anchor" href="#discussion"><i class="fas fa-link"></i></a>
</h2>
<div id="sampling-case-study" class="section level3" number="6.5.1">
<h3>
<span class="header-section-number">6.5.1</span> Case study: Polls<a class="anchor" aria-label="anchor" href="#sampling-case-study"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s now switch gears to a more realistic sampling scenario: a poll. In practice, pollsters do not take 1,000 repeated samples as we did in our previous sampling activities, but rather take only a <em>single sample</em> that’s as large as possible.</p>
<p>On December 4, 2013, National Public Radio in the US reported on a poll of President Obama’s approval rating among young Americans aged 18-29 in an article, <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">“Poll: Support For Obama Among Young Americans Eroding.”</a> The poll was conducted by the Kennedy School’s Institute of Politics at Harvard University. A quote from the article:</p>
<blockquote>
<p>After voting for him in large numbers in 2008 and 2012, young Americans are souring on President Obama.</p>
<p>According to a new Harvard University Institute of Politics poll, just 41 percent of millennials — adults ages 18-29 — approve of Obama’s job performance, his lowest-ever standing among the group and an 11-point drop from April.</p>
</blockquote>
<p>Let’s tie elements of the real life poll in this new article with our “tactile” and “virtual” urn activity from Sections <a href="one-parameter.html#sampling-activity">6.1</a> and <a href="one-parameter.html#virtual-sampling">6.2</a> using the terminology, notations, and definitions we learned in Section <a href="one-parameter.html#standard-errors">6.3</a>. You’ll see that our sampling activity with the urn is an idealized version of what pollsters are trying to do in real life.</p>
<!-- RS: I love the way this section uses the vocabulary, and I think this should be replicated everywhere else in the chapter. Very helpful to see the meaning of each word in practice. Maybe add mention to the first cardinal value when setting up the problem to really teach the concept? -->
<p>First, who is the <strong>(Study) Population</strong> of <span class="math inline">\(N\)</span> individuals or observations of interest?</p>
<ul>
<li>Urn: <span class="math inline">\(N\)</span> = 1000 identically sized red and white beads</li>
<li>Obama poll: <span class="math inline">\(N\)</span> = ? young Americans aged 18-29</li>
</ul>
<p>Second, what is the <strong>population parameter</strong>?</p>
<ul>
<li>Urn: The population proportion <span class="math inline">\(\rho\)</span> of <em>all</em> the beads in the urn that are red.</li>
<li>Obama poll: The population proportion <span class="math inline">\(\rho\)</span> of <em>all</em> young Americans who approve of Obama’s job performance.</li>
</ul>
<p>Third, what would a <strong>census</strong> look like?</p>
<ul>
<li>Urn: Manually going over all <span class="math inline">\(N\)</span> = 1000 beads and exactly computing the population proportion <span class="math inline">\(\rho\)</span> of the beads that are red.</li>
<li>Obama poll: Locating all <span class="math inline">\(N\)</span> young Americans and asking them all if they approve of Obama’s job performance. In this case, we don’t even know what the population size <span class="math inline">\(N\)</span> is!</li>
</ul>
<p>Fourth, how do you perform <strong>sampling</strong> to obtain a sample of size <span class="math inline">\(n\)</span>?</p>
<ul>
<li>Urn: Using a shovel with <span class="math inline">\(n\)</span> slots.</li>
<li>Obama poll: One method is to get a list of phone numbers of all young Americans and pick out <span class="math inline">\(n\)</span> phone numbers. In this poll’s case, the sample size of this poll was <span class="math inline">\(n = 2089\)</span> young Americans.</li>
</ul>
<p>Fifth, what is your <strong>point estimate (AKA sample statistic)</strong> of the unknown population parameter?</p>
<ul>
<li>Urn: The sample proportion <span class="math inline">\(\hat{\rho}\)</span> of the beads in the shovel that were red.</li>
<li>Obama poll: The sample proportion <span class="math inline">\(\hat{\rho}\)</span> of young Americans in the sample that approve of Obama’s job performance. In this poll’s case, <span class="math inline">\(\hat{\rho} = 0.41 = 41\%\)</span>, the quoted percentage in the second paragraph of the article.</li>
</ul>
<p>Sixth, is the sampling procedure <strong>representative</strong>?</p>
<ul>
<li>Urn: Are the contents of the shovel representative of the contents of the urn? Because we mixed the urn before sampling, we can feel confident that they are.</li>
<li>Obama poll: Is the sample of <span class="math inline">\(n = 2089\)</span> young Americans representative of <em>all</em> young Americans aged 18-29? This depends on whether the sampling was random.</li>
</ul>
<!-- RS: Also describe the differences between the real urn and the virtual urn, and that the virtual urn is much simpler than real life because the samples are truly random. --><p>Seventh, are the samples <strong>generalizable</strong> to the greater population?</p>
<ul>
<li>Urn: Is the sample proportion <span class="math inline">\(\hat{\rho}\)</span> of the shovel’s beads that are red a “good guess” of the population proportion <span class="math inline">\(\rho\)</span> of the urn’s beads that are red? Given that the sample was representative, the answer is yes.</li>
<li>Obama poll: Is the sample proportion <span class="math inline">\(\hat{\rho} = 0.41\)</span> of the sample of young Americans who supported Obama a “good guess” of the population proportion <span class="math inline">\(\rho\)</span> of all young Americans who supported Obama at this time in 2013? In other words, can we confidently say that roughly 41% of <em>all</em> young Americans approved of Obama at the time of the poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Eighth, is the sampling procedure <strong>unbiased</strong>? In other words, do all observations have an equal chance of being included in the sample?</p>
<ul>
<li>Urn: Since each bead was equally sized and we mixed the urn before using the shovel, each bead had an equal chance of being included in a sample and hence the sampling was unbiased.</li>
<li>Obama poll: Did all young Americans have an equal chance at being represented in this poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Ninth and lastly, was the sampling done at <strong>random</strong>?</p>
<ul>
<li>Urn: As long as you mixed the urn sufficiently before sampling, your samples would be random.</li>
<li>Obama poll: Was the sample conducted at random? We can’t answer this question without knowing about the <em>sampling methodology</em> used by Kennedy School’s Institute of Politics at Harvard University. We’ll discuss this more at the end of this section.</li>
</ul>
<p>In other words, the poll by Kennedy School’s Institute of Politics at Harvard University can be thought of as <em>an instance</em> of using the shovel to sample beads from the urn. Furthermore, if another polling company conducted a similar poll of young Americans at roughly the same time, they would likely get a different estimate than 41%. This is due to <em>sampling variation</em>.</p>
<p>Let’s now revisit the sampling paradigm from Subsection <a href="one-parameter.html#terminology-and-notation">6.3.1</a>:</p>
<p><strong>In general</strong>:</p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>“good guess”</strong> of the unknown population parameter, thus</li>
<li>instead of performing a census, we can <strong>infer</strong> about the population using sampling.</li>
</ul>
<p><strong>Specific to the urn:</strong></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n = 50\)</span> beads at <strong>random</strong>, in other words, we mix all of the equally sized beads before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn’s 1000 beads, thus</li>
<li>any result based on the shovel’s beads can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\hat{\rho}\)</span> of the <span class="math inline">\(n = 50\)</span> beads in the shovel that are red is a <strong>“good guess”</strong> of the population proportion <span class="math inline">\(\rho\)</span> of the <span class="math inline">\(N = 1000\)</span> beads that are red, thus</li>
<li>instead of manually going over all 1000 beads in the urn, we can <strong>infer</strong> about the urn using the shovel.</li>
</ul>
<p><strong>Specific to the Obama poll:</strong></p>
<ul>
<li>If we had a way of contacting a <strong>randomly</strong> chosen sample of 2089 young Americans and polling their approval of President Obama in 2013, then</li>
<li>these 2089 young Americans would be an <strong>unbiased</strong> and <strong>representative</strong> sample of <em>all</em> young Americans in 2013, thus</li>
<li>any results based on this sample of 2089 young Americans can <strong>generalize</strong> to the entire population of <em>all</em> young Americans in 2013, thus</li>
<li>the reported sample approval rating of 41% of these 2089 young Americans is a <strong>good guess</strong> of the true approval rating among all young Americans in 2013, thus</li>
<li>instead of performing an expensive census of all young Americans in 2013, we can <strong>infer</strong> about all young Americans in 2013 using polling.</li>
</ul>
<p>So as you can see, it was critical for the sample obtained by Kennedy School’s Institute of Politics at Harvard University to be truly random in order to infer about <em>all</em> young Americans’ opinions about Obama. Was their sample truly random? It’s hard to answer such questions without knowing about the <em>sampling methodology</em> they used.</p>
<p>For example, what if Kennedy School’s Institute of Politics at Harvard University conducted this poll using only mobile phone numbers? People without mobile phones would be left out and therefore not represented in the sample. This flaw is an example of <strong>censoring</strong>, the exclusion of certain datapoints due to an issue with data collection. This results in an incomplete observation and increases the prediction uncertainty of the estimand, Obama’s approval rating among young Americans. Ensuring that our samples were random was easy to do in our sampling urn exercises; however, in a real life situation like the Obama poll, this is much harder to do.</p>
<p>What you have visualized in this chapter was a demonstration of a famous theorem, or mathematically proven truth, called the <em>Central Limit Theorem</em>. It loosely states that when sample means are based on larger and larger sample sizes, the sampling distribution of these sample means becomes both more and more normally shaped and more and more narrow. In other words, the sampling distribution increasingly follows a <em>normal distribution</em> and the variation of these sampling distributions gets smaller, as quantified by their standard errors.</p>
<!-- RS: Add back discussion on sampling mechanisms but w/ Obama census.  -->
<!-- RS: I definetly support further exploring the Kennedy study further in this chapter, or in the tutorial because I feel like it would be much more informative than redoing the urn problem.  -->
<!-- RS: Consider a brief section about observational study design? I know this isn't a stats class, but might be useful to at least discuss bad sampling methods (volunteer surveys, convienence, and other types of biases. ) -->
</div>
<div id="precision-versus-accuracy-or-bias-versus-variance" class="section level3" number="6.5.2">
<h3>
<span class="header-section-number">6.5.2</span> Precision versus accuracy (or bias versus variance)<a class="anchor" aria-label="anchor" href="#precision-versus-accuracy-or-bias-versus-variance"><i class="fas fa-link"></i></a>
</h3>
<p>We saw in a previous section that as our sample size <span class="math inline">\(n\)</span> increases, our point estimates will vary less and less and be more and more concentrated around the true population parameter. This variation is quantified by the decreasing <em>standard error</em>. In other words, the typical error of your point estimates will decrease. In our sampling exercise, as the sample size increased, the variation of our sample proportions <span class="math inline">\(\hat{\rho}\)</span> decreased. This is also known as having a <em>precise</em> estimate.</p>
<p>So random sampling ensures our point estimates are <em>accurate</em>, while on the other hand having a large sample size ensures our point estimates are <em>precise</em>. While the terms “accuracy” and “precision” may sound like they mean the same thing, there is a subtle difference. Accuracy describes how “on target” our estimates are, whereas precision describes how “consistent” our estimates are. The image below illustrates the difference.</p>
<div class="figure">
<span id="fig:unnamed-chunk-518"></span>
<img src="06-one-parameter/images/accuracy_vs_precision.jpg" alt="Comparing accuracy and precision." width="100%"><p class="caption">
FIGURE 6.24: Comparing accuracy and precision.
</p>
</div>
<p>Now, it’s obvious that the best case scenario is the most precise and the most accurate option. However, real life sampling isn’t so easy!</p>
<p>What if we had the option to use a shovel with <strong>200</strong> slots, but it had a minor magnetic property that caused it to pick up slightly more red beads than the 100 slotted shovel? On one hand, the larger shovel gives us increased precision due to a larger sample size. On the other, its magnetic property gives us decreased accuracy due to a sampling bias. Here, as is often the case in the real world, there is a tradeoff!</p>
</div>
</div>
<div id="summary-6" class="section level2" number="6.6">
<h2>
<span class="header-section-number">6.6</span> Summary<a class="anchor" aria-label="anchor" href="#summary-6"><i class="fas fa-link"></i></a>
</h2>
<p>Key lesson:</p>
<p>There is a truth! There is a true value for <span class="math inline">\(\rho\)</span> which we do not know! We want to create a posterior probability distribution which summarizes our knowledge. We care about the posterior probability distribution of p. The center of that distribution is around the mean or median of the proportion in your sample. The sd (or mad) of that posterior is the standard deviation divided by the square root of our sample size! Note that this is the same thing as the standard deviation of the repeated samples.</p>
<p>Key lesson:</p>
<p>We have a journey from reality, to our predictions, to the standard error of our predictions, to the posterior probability distribution for p. This is our sequence:</p>
<p><strong>p (the truth) <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat{\rho}\)</span> (my estimate) <span class="math inline">\(\Rightarrow\)</span> the standard error of <span class="math inline">\(\hat{\rho}\)</span> (black box of math mumbo jumbo and computer simulation magic) <span class="math inline">\(\Rightarrow\)</span> our posterior probability distribution for p (our beliefs about the truth).</strong></p>
<p>This journey shows how our beliefs about the truth develop through our work. We begin with p; p is the truth, the true but unknown value we are estimating. <span class="math inline">\(\hat{\rho}\)</span> is our estimate for p. There can be millions and millions of <span class="math inline">\(\hat{\rho}\)</span>’s. Next, we must take the standard error of our estimates (our <span class="math inline">\(\hat{\rho}\)</span>’s) to account for our uncertainty with our predictions. Finally – the thing we need most – we create a posterior probability distribution for p. This distribution is used to answer key questions about p. </p>
<p>Other highlights:</p>
<div id="tactial-sampling" class="section level3" number="6.6.1">
<h3>
<span class="header-section-number">6.6.1</span> Tactial sampling<a class="anchor" aria-label="anchor" href="#tactial-sampling"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Sampling allows us to make guesses at an unknown, difficult-to-obtain value by looking at a smaller subset of data and generalizing it to the larger population.</li>
<li>Sampling is preferable in the urn example because counting out 1000 beads from an urn is intensive and tedious.</li>
<li>Sampling is preferable in the real-world because it is often impossible to sample “all the beads” (all the people) in a population. With sampling, you see variations in your results. This is known as sampling variation and is expected, especially if you draw samples at random (unbiased).</li>
</ul>
</div>
<div id="virtual-sampling-1" class="section level3" number="6.6.2">
<h3>
<span class="header-section-number">6.6.2</span> Virtual sampling<a class="anchor" aria-label="anchor" href="#virtual-sampling-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>By creating a virtual analog of our urn and our shovel, we were able to look at <em>even more</em> samples and observe the effects of sampling size on our results.</li>
<li>More samples yield more even distributions which should resemble a bell.</li>
<li>Larger sample sizes decrease standard deviation, meaning that the resulting proportions red are closer to one another than when the sample sizes are smaller. This means that larger samples = lower SD = more precise guesses.</li>
<li>When we are writing a lot of code for something we want to perform frequently, write a function instead! This saves time and functions can be called within <code>map()</code> for more ease when plotting results.</li>
</ul>
</div>
<div id="standard-error" class="section level3" number="6.6.3">
<h3>
<span class="header-section-number">6.6.3</span> Standard error<a class="anchor" aria-label="anchor" href="#standard-error"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Standard error is just a fancy term for your uncertainty about something you don’t know. Standard error <span class="math inline">\(\approx\)</span> our (uncertain) beliefs.</li>
<li>The standard error measures the accuracy of a sample distribution as compared to the population by using the standard deviation.</li>
<li>We find that larger sample sizes <span class="math inline">\(\implies\)</span> lower standard errors <span class="math inline">\(\implies\)</span> more accurate estimates.<br>
</li>
<li>If we could only know two pieces of information from our data, we would need a measure of the <strong>center</strong> of the distribution (like mean or median) and a measure of the <strong>variability</strong> of the distribution (like sd or MAD).</li>
<li>SE refers to the standard deviation of a sample statistic (aka point estimate), such as the mean or median. Therefore, the “standard error of the mean” refers to the standard deviation of the distribution of sample means taken from a population.</li>
</ul>
</div>
<div id="answering-the-questions-1" class="section level3" number="6.6.4">
<h3>
<span class="header-section-number">6.6.4</span> Answering the questions<a class="anchor" aria-label="anchor" href="#answering-the-questions-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<code><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm()</a></code> can create a joint distribution and then estimate the posterior probability distribution, conditional on the data which was passed in to the data argument. This is a much easier way to create the posterior distribution, and will be explored in more detail in Chapter <a href="two-parameters.html#two-parameters">7</a>.</li>
</ul>
</div>
<div id="discussion-1" class="section level3" number="6.6.5">
<h3>
<span class="header-section-number">6.6.5</span> Discussion<a class="anchor" aria-label="anchor" href="#discussion-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>The sampling mechanism is responsible for which items/beads/people/etc are selected to be sampled. In the urn example, the <em>sampling mechanism</em> is the shovel.</li>
<li>Random sampling ensures that our point estimates are <strong>accurate</strong>, while having a large sample size ensures that our estimates are <strong>precise</strong>. The difference between precision and accuracy is important if we are to make informed estimates.</li>
<li>Real life sampling is <em>extremely</em> prone to error. This cannot be emphasized enough. We are often forced to choose between precision and accuracy during real-life sampling.</li>
</ul>
<p>In this chapter, we performed both tactile and virtual sampling exercises to infer about an unknown parameter We also presented a case study of sampling in real life with polls. In each case, we used the sample proportion <span class="math inline">\(\hat{\rho}\)</span> to estimate the population proportion <span class="math inline">\(\rho\)</span>. However, we are not just limited to scenarios related to proportions. In other words, we can use sampling to estimate other population parameters using other point estimates as well.</p>
<p>As we continue our journey, recall the case of Primrose Everdeen and what she represents: no matter how realistic is our model is, our predictions are <strong>never certain</strong>.</p>
<div class="inline-figure"><img src="06-one-parameter/images/posterior_effie.png" width="100%"></div>
<!-- RS: The conclusion of this chapter (6.4 and 6.5) is really exceptional. Honestly the start of the chapter can be kind of confusing, and it would be less so if it was structured like the conclusion.  -->
<!-- RS: Overall, the start and the end of the chapter is good, but the middle has some confusing vocab mixups and it is not very helpful to teach someone how to actually approch the problem. I also support utilizing real world studies more either in the primer or the tutotial (like the Kennedy study. ) -->

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="probability.html"><span class="header-section-number">5</span> Probability</a></div>
<div class="next"><a href="two-parameters.html"><span class="header-section-number">7</span> Two Parameters</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#one-parameter"><span class="header-section-number">6</span> One Parameter</a></li>
<li>
<a class="nav-link" href="#sampling-activity"><span class="header-section-number">6.1</span> Real sampling activity</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#using-the-shovel-method-once"><span class="header-section-number">6.1.1</span> Using the shovel method once</a></li>
<li><a class="nav-link" href="#student-shovels"><span class="header-section-number">6.1.2</span> Using the shovel 33 times</a></li>
<li><a class="nav-link" href="#what-did-we-just-do"><span class="header-section-number">6.1.3</span> What did we just do?</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#virtual-sampling"><span class="header-section-number">6.2</span> Virtual sampling</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#shovel-one-time"><span class="header-section-number">6.2.1</span> Using the virtual shovel once</a></li>
<li><a class="nav-link" href="#shovel-33-times"><span class="header-section-number">6.2.2</span> Using the virtual shovel 33 times</a></li>
<li><a class="nav-link" href="#shovel-1000-times"><span class="header-section-number">6.2.3</span> Using the virtual shovel 1,000 times</a></li>
<li><a class="nav-link" href="#different-shovels"><span class="header-section-number">6.2.4</span> The effect of different shovel sizes</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#standard-errors"><span class="header-section-number">6.3</span> Standard error</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#terminology-and-notation"><span class="header-section-number">6.3.1</span> Terminology and notation</a></li>
<li><a class="nav-link" href="#sampling-definitions"><span class="header-section-number">6.3.2</span> Statistical definitions</a></li>
<li><a class="nav-link" href="#what-is-a-standard-error"><span class="header-section-number">6.3.3</span> What is a “standard error?”</a></li>
<li><a class="nav-link" href="#moral-of-the-story"><span class="header-section-number">6.3.4</span> The moral of the story</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#urn-paradigm"><span class="header-section-number">6.4</span> Urn paradigm</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wisdom-1"><span class="header-section-number">6.4.1</span> Wisdom</a></li>
<li><a class="nav-link" href="#justice-1"><span class="header-section-number">6.4.2</span> Justice</a></li>
<li><a class="nav-link" href="#courage-1"><span class="header-section-number">6.4.3</span> Courage</a></li>
<li><a class="nav-link" href="#temperance-1"><span class="header-section-number">6.4.4</span> Temperance</a></li>
<li><a class="nav-link" href="#cardinal-virtues-1"><span class="header-section-number">6.4.5</span> Cardinal virtues</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#discussion"><span class="header-section-number">6.5</span> Discussion</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sampling-case-study"><span class="header-section-number">6.5.1</span> Case study: Polls</a></li>
<li><a class="nav-link" href="#precision-versus-accuracy-or-bias-versus-variance"><span class="header-section-number">6.5.2</span> Precision versus accuracy (or bias versus variance)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#summary-6"><span class="header-section-number">6.6</span> Summary</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tactial-sampling"><span class="header-section-number">6.6.1</span> Tactial sampling</a></li>
<li><a class="nav-link" href="#virtual-sampling-1"><span class="header-section-number">6.6.2</span> Virtual sampling</a></li>
<li><a class="nav-link" href="#standard-error"><span class="header-section-number">6.6.3</span> Standard error</a></li>
<li><a class="nav-link" href="#answering-the-questions-1"><span class="header-section-number">6.6.4</span> Answering the questions</a></li>
<li><a class="nav-link" href="#discussion-1"><span class="header-section-number">6.6.5</span> Discussion</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PPBDS/primer/blob/master/06-one-parameter.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PPBDS/primer/edit/master/06-one-parameter.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Preceptor’s Primer for Bayesian Data Science</strong>" was written by David Kane. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
